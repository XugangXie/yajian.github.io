<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="google-site-verification" content="iuqAv5dkTjkC-tYrbkff9KGsw2tnVjzlEHIubXlnmaI">








  <meta name="baidu-site-verification" content="FKXU75MFl1">







  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css">



  <link rel="icon" type="image/png" sizes="32x32" href="/images/iris_32*32.ico?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/iris_16*16.ico?v=5.1.3">






  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="小建儿的小站" type="application/atom+xml">






  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice")
  daovoice('init', {
      app_id: "84485d15"
    });
  daovoice('update');
  </script>



<meta name="description" content="码农小白成长记">
<meta property="og:type" content="website">
<meta property="og:title" content="小建儿的小站">
<meta property="og:url" content="http://yajian.github.io/index.html">
<meta property="og:site_name" content="小建儿的小站">
<meta property="og:description" content="码农小白成长记">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="小建儿的小站">
<meta name="twitter:description" content="码农小白成长记">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yajian.github.io/">





  <title>小建儿的小站</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">小建儿的小站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tag"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yajian.github.io/从决策树到xgboost/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小建儿">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小建儿的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/从决策树到xgboost/" itemprop="url">从决策树到xgboost</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-20T19:34:46+08:00">
                2018-12-20
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/从决策树到xgboost/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="从决策树到xgboost/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>&emsp;&emsp;xgboost(Extreme Gradient Boosting)是一款常用的机器学习框架，其诞生于2014年12月，因具有良好的学习效果以及高效的训练速度得到广泛关注。仅在2015年，在Kaggle竞赛中获胜的29个算法中，有17个使用了XGBoost库，而作为对比，近年大热的深度神经网络方法，这一数据则是11个。在KDDCup 2015竞赛中，排名前十的队伍全部使用了XGBoost库。XGBoost不仅学习效果很好，而且速度也很快，相比梯度提升算法在另一个常用机器学习库scikit-learn中的实现，XGBoost的性能经常有十倍以上的提升。</p>
<p>&emsp;&emsp;xgboost与另一种ensemble模型gbdt(Gradient boosting decision tree)有着紧密的联系，两者均与决策树、提升模型、梯度提升等概念相关。本文从决策树出发，逐步进行xgboost推导，并结合实例分析手动计算过程，最终给出代码实现，希望有助于大家理解xgboost相关原理。</p>
<h1 id="决策树-Decision-Tree"><a href="#决策树-Decision-Tree" class="headerlink" title="决策树(Decision Tree)"></a>决策树(Decision Tree)</h1><p>&emsp;&emsp;决策树是传统机器学习中常见的一种模型，其易于理解，可解释性强，计算速度快。</p>
<h2 id="分类决策树"><a href="#分类决策树" class="headerlink" title="分类决策树"></a>分类决策树</h2><p>&emsp;&emsp;构建分类决策树模型的过程中最关键的步骤在于如何选择结点分裂准则，常见的分裂准则有ID3、C4.5等，相关概念可参考<a href="https://yajian.github.io/%E5%86%B3%E7%AD%96%E6%A0%91/">决策树</a>。</p>
<h2 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h2><p>&emsp;&emsp;CART模型是决策树中比较特殊的一种模型，其既可以用于分类又可以用于回归预测，分类树采用基尼指数最小化准则，回归采用平方误差最小化准备，相关概念可参考<a href="https://yajian.github.io/CART-%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92%E6%A0%91/">CART-分类与回归树</a>。</p>
<h1 id="提升树-Boosting-Tree"><a href="#提升树-Boosting-Tree" class="headerlink" title="提升树(Boosting Tree)"></a>提升树(Boosting Tree)</h1><h2 id="提升方法-boosting"><a href="#提升方法-boosting" class="headerlink" title="提升方法(boosting)"></a>提升方法(boosting)</h2><p>&emsp;&emsp;提升方法的思想：对于一个复杂任务来说，将多个专家系统的判断进行适当的综合所得出的判断，要比其中任何一个专家单独的判断好，简而言之就是“三个臭皮匠顶个诸葛亮”的道理。</p>
<p>&emsp;&emsp;对于分类问题而言，给定一个训练样本集，求比较粗糙的分类规则（弱分类器）要求比精确的分类规则（强分类器）容易得多。提升方法就是从弱学习算法出发，反复学习，得到一系列弱分类器，然后组合这些弱分类器，构成一个强分类器。</p>
<h3 id="加法模型"><a href="#加法模型" class="headerlink" title="加法模型"></a>加法模型</h3><p>&emsp;&emsp;加法模型表示如下</p>
<p>$$f(x)=\sum_{m=1}^{M}\beta_mb(x;\gamma_m)$$<br>其中$b(x;\gamma_m)$为基函数，$\gamma_m$为基函数的参数，$\beta_mb$为基函数的系数。</p>
<ul>
<li>注：傅立叶变换可以看成一种加法模型</li>
</ul>
<h3 id="前向分布算法"><a href="#前向分布算法" class="headerlink" title="前向分布算法"></a>前向分布算法</h3><p>&emsp;&emsp;在给定训练数据和损失函数$L(y,f(x))$的情况下，学习加法模型$f(x)$成为经验风险极小化问题：</p>
<p>$$min_{\beta_m,\gamma_m}\sum_{i=1}^{N}L[y_i,\sum_{m=1}^{M}\beta_mb(x_i;\gamma_m)]$$</p>
<p>使用前向分布算法解决这一优化问题的思路是：因为学习的是加法模型，如何能够从前向后，每一步只学习一个基函数及其系数，逐步逼近优化目标函数，就可以简化优化的复杂度。具体地，只需优化如下损失函数：</p>
<p>$$min_{\beta,\gamma}\sum_{i=1}^{N}L(y_i,\beta b(x_i;\gamma))$$</p>
<h2 id="提升树模型"><a href="#提升树模型" class="headerlink" title="提升树模型"></a>提升树模型</h2><p>&emsp;&emsp;以决策树为基函数的提升方法称为提升树。提升树模型可以表示为决策树的加法模型</p>
<p>$$f_M(x)=\sum_{m=1}^{M}T(x,\Theta_m)$$</p>
<p>其中$T(x,\Theta_m)$表示决策树，$\Theta_m$表示决策树的参数， $M$表示决策树的个数。对于分类问题决策树采用二叉分类树，对于回归问题决策树采用二叉回归树。</p>
<!--&emsp;&emsp;假设给定训练数据集$D={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}$，输入空间划分为$J$个单元$R_1,R_2,...,R_j$，并且在每个单元$R_j$上有一个固定的输出值$c_j$，于是回归树模型可以表示为

$$T(x,\Theta) = \sum_{j=1}^{J}c_jI(x \in R_j)$$

其中函数$I$为指示函数，参数$\Theta={(R_1,c_1),(R_2,c_2),...,(R_J,c_J)}$表示树的区域划分和各区域上的常数，$J$是回归树的复杂度即叶结点的个数。-->
<p>&emsp;&emsp;前向回归算法：</p>
<p>$$<br>\begin{split}<br>    f_0(x) &amp;= 0 \\<br>    f_m(x) &amp;= f_{m-1}(x)+T(x;\Theta_m),\quad m=1,2,…,M \\<br>    f_M(x) &amp;= \sum_{m=1}^{M}T(x;\Theta_m)<br>    \end{split}<br>$$</p>
<p>给定当前模型$f_{m-1}(x)$，需求解，<br>$$<br>\hat \Theta_m=\mathop{\arg\min}_{\Theta_m}\sum_{i=1}^{N}L(y_i,f_{m-1}(x_i)+T(x;\Theta_m))<br>$$</p>
<p>得到$\hat \Theta_m$即，第$m$棵树的参数。</p>
<p>&emsp;&emsp;当使用平方误差损失函数的时候，<br>$$L(y,f(x))=(y-f(x))^2$$</p>
<p>其损失变为</p>
<p>$$<br>\begin{split}<br>    L(y,f_{m-1}(x)+T_m(x;\Theta))&amp;=[y-f_{m-1}(x) - T_m(x;\Theta)]^2\\<br>    &amp;=[r-T_m(x;\Theta)]^2<br>\end{split}<br>$$</p>
<p>其中$r=y-f_{m-1}(x)$就是当前拟合数据的残差。所以对于回归问题（回归问题的损失函数一般为MSE）的提升树算法来说，只需要简单拟合当前模型的残差。</p>
<h1 id="梯度提升决策树-GBDT"><a href="#梯度提升决策树-GBDT" class="headerlink" title="梯度提升决策树(GBDT)"></a>梯度提升决策树(GBDT)</h1><p>&emsp;&emsp;提升树利用加法模型与前向分布算法实现学习的优化过程，当损失函数是平方损失函数时，每一步优化比较简单。但对于一般损失函数而言，往往每一步优化并不那么容易，所以需要寻找其他方式求解。</p>
<p>&emsp;&emsp;损失函数如下<br>$$<br>L(\Theta_m)=\sum_{i=1}^{N}L(y_i,f_{m-1}(x_i)+T(x;\Theta_m))<br>\tag{4.1}<br>$$</p>
<p>我们的目的是让4.1式最小，尝试用泰勒一阶展开有</p>
<p>$$<br>    L(\Theta_m) \approx \sum_{i=1}^{N}[L(y_i,f_{m-1}(x_i)) + \frac{\partial{L(y_i,f_{m-1}(x_i))}}{\partial{L(f_{m-1}(x_i))}} \cdot T(x;\Theta_m)]<br>\tag{4.2}<br>$$</p>
<ul>
<li>注： 泰勒一阶展开公式$f(x+\Delta x)=f(x) + \frac{\partial f(x)}{\partial x} \cdot \Delta x$</li>
</ul>
<p>由于迭代后损失函数减小，所以<br>$$<br>L(\Theta_m)- \sum_{i=1}^{N}L(y_i,f_{m-1}(x_i))&lt;0<br>$$<br>即<br>$$<br>\sum_{i=1}^{N}[\frac{\partial{L(y_i,f_{m-1}(x_i))}}{\partial{L(f_{m-1}(x_i))}} \cdot T(x;\Theta_m)]&lt;0<br>\tag{4.3}<br>$$<br>如果让提升树$T(x;\Theta_m)$每次拟合$L(y_i,f_{m-1}(x_i))$的负梯度</p>
<p>$$<br>    T(x;\Theta_m)=-\frac{\partial{L(y_i,f_{m-1}(x_i))}}{\partial{L(f_{m-1}(x_i))}}<br>    \tag{4.4}<br>$$<br>可以保证4.3式始终小于0。</p>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>&emsp;&emsp;训练数据如下表所示，$x$的取值范围为区间$[0.5,10.5]$，$y$的取值范围为区间$[5.0,10.0]$，使用GBDT算法解决该回归问题。</p>
<table>
<thead>
<tr>
<th style="text-align:center">x</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">5</th>
<th style="text-align:center">6</th>
<th style="text-align:center">7</th>
<th style="text-align:center">8</th>
<th style="text-align:center">9</th>
<th style="text-align:center">10</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">y</td>
<td style="text-align:center">5.56</td>
<td style="text-align:center">5.7</td>
<td style="text-align:center">5.91</td>
<td style="text-align:center">6.4</td>
<td style="text-align:center">6.8</td>
<td style="text-align:center">7.05</td>
<td style="text-align:center">8.9</td>
<td style="text-align:center">8.7</td>
<td style="text-align:center">9</td>
<td style="text-align:center">9.05</td>
</tr>
</tbody>
</table>
<p>&emsp;&emsp;回归问题的损失函数使用平方误差损失函数，所以该问题退化为使用回归树拟合残差。</p>
<ul>
<li>求解第一棵回归树</li>
</ul>
<p>&emsp;&emsp;由于只有$x$一个变量，因此最优切分变量为$x$。接下来假设9个切分点为$[1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5]$，计算每个切分点的输出值。如$s=1.5$时，$R_1={1},R_2={2,3,4,5,6,7,8,9,10}$，这两个区域的输出值分别为$c_1=5.56,c_2=\frac{1}{9}(5.7+5.91+6.4+6.8+7.05+8.9+8.7+9+9.05)=7.50$，所以有</p>
<table>
<thead>
<tr>
<th style="text-align:center">s</th>
<th style="text-align:center">1.5</th>
<th style="text-align:center">2.5</th>
<th style="text-align:center">3.5</th>
<th style="text-align:center">4.5</th>
<th style="text-align:center">5.5</th>
<th style="text-align:center">6.5</th>
<th style="text-align:center">7.5</th>
<th style="text-align:center">8.5</th>
<th style="text-align:center">9.5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$c_1$</td>
<td style="text-align:center">5.56</td>
<td style="text-align:center">5.63</td>
<td style="text-align:center">5.72</td>
<td style="text-align:center">5.89</td>
<td style="text-align:center">6.07</td>
<td style="text-align:center">6.24</td>
<td style="text-align:center">6.62</td>
<td style="text-align:center">6.88</td>
<td style="text-align:center">7.11</td>
</tr>
<tr>
<td style="text-align:center">$c_2$</td>
<td style="text-align:center">7.5</td>
<td style="text-align:center">7.73</td>
<td style="text-align:center">7.99</td>
<td style="text-align:center">8.25</td>
<td style="text-align:center">8.54</td>
<td style="text-align:center">8.91</td>
<td style="text-align:center">8.92</td>
<td style="text-align:center">9.03</td>
<td style="text-align:center">9.05</td>
</tr>
</tbody>
</table>
<p>接下来计算每个切分点的误差，如$s=1.5$时，$loss(s=1.5)=\frac{1}{2}(5.56-5.56)^2+\sum_{i=2}^{10}\frac{1}{2}(y_i-7.5)^2=0+15.72=15.72$，所以有</p>
<table>
<thead>
<tr>
<th style="text-align:center">s</th>
<th style="text-align:center">1.5</th>
<th style="text-align:center">2.5</th>
<th style="text-align:center">3.5</th>
<th style="text-align:center">4.5</th>
<th style="text-align:center">5.5</th>
<th style="text-align:center">6.5</th>
<th style="text-align:center">7.5</th>
<th style="text-align:center">8.5</th>
<th style="text-align:center">9.5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$loss(s)$</td>
<td style="text-align:center">15.72</td>
<td style="text-align:center">12.07</td>
<td style="text-align:center">8.36</td>
<td style="text-align:center">5.78</td>
<td style="text-align:center">3.91</td>
<td style="text-align:center">1.93</td>
<td style="text-align:center">8.01</td>
<td style="text-align:center">11.73</td>
<td style="text-align:center">15.74</td>
</tr>
</tbody>
</table>
<p>其中当$s=6.5$时，$loss(s)$最小，因此第一个划分变量是$j=x,s=6.5$。所以回归树为</p>
<p>$$<br>    T_1(x) = \begin{cases}<br>                    6.24\quad x \lt 6.5 \\<br>                    8.91 \quad  x \geq 6.5 \\<br>                \end{cases}<br>$$<br>$$    f_1(x) = T_1(x)$$<br>残差为$r_{2i}= y_i - f_1(x)$，如下</p>
<table>
<thead>
<tr>
<th style="text-align:center">$x_i$</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">5</th>
<th style="text-align:center">6</th>
<th style="text-align:center">7</th>
<th style="text-align:center">8</th>
<th style="text-align:center">9</th>
<th style="text-align:center">10</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$r_{2i}$</td>
<td style="text-align:center">-0.68</td>
<td style="text-align:center">-0.54</td>
<td style="text-align:center">-0.33</td>
<td style="text-align:center">0.16</td>
<td style="text-align:center">0.56</td>
<td style="text-align:center">0.81</td>
<td style="text-align:center">-0.01</td>
<td style="text-align:center">-0.21</td>
<td style="text-align:center">0.09</td>
<td style="text-align:center">0.14</td>
</tr>
</tbody>
</table>
<p>$$L(y,f_1(x)) = \sum_{i=1}^{10}(y_i-f_1(x))^2=1.93$$</p>
<ul>
<li>接下来对上一步残差进行拟合</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">s</th>
<th style="text-align:center">1.5</th>
<th style="text-align:center">2.5</th>
<th style="text-align:center">3.5</th>
<th style="text-align:center">4.5</th>
<th style="text-align:center">5.5</th>
<th style="text-align:center">6.5</th>
<th style="text-align:center">7.5</th>
<th style="text-align:center">8.5</th>
<th style="text-align:center">9.5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$c_1$</td>
<td style="text-align:center">-0.68</td>
<td style="text-align:center">-0.61</td>
<td style="text-align:center">-0.52</td>
<td style="text-align:center">-0.35</td>
<td style="text-align:center">-0.17</td>
<td style="text-align:center">-0.003</td>
<td style="text-align:center">-0.004</td>
<td style="text-align:center">-0.03</td>
<td style="text-align:center">-0.02</td>
</tr>
<tr>
<td style="text-align:center">$c_2$</td>
<td style="text-align:center">0.07</td>
<td style="text-align:center">0.15</td>
<td style="text-align:center">0.22</td>
<td style="text-align:center">0.23</td>
<td style="text-align:center">0.164</td>
<td style="text-align:center">0.003</td>
<td style="text-align:center">0.01</td>
<td style="text-align:center">0.12</td>
<td style="text-align:center">0.14</td>
</tr>
<tr>
<td style="text-align:center">$loss(s)$</td>
<td style="text-align:center">0.71</td>
<td style="text-align:center">0.50</td>
<td style="text-align:center">0.40</td>
<td style="text-align:center">0.56</td>
<td style="text-align:center">0.83</td>
<td style="text-align:center">0.97</td>
<td style="text-align:center">0.97</td>
<td style="text-align:center">0.95</td>
<td style="text-align:center">0.95</td>
</tr>
</tbody>
</table>
<p>其中当$s=3.5$时，$loss(s)$最小，因此第一个划分变量是$j=x,s=3.5$。<br>所以回归树为<br>    $$<br>        T_2(x) = \begin{cases}<br>                        -0.52\quad x \lt 3.5 \\<br>                        0.22 \quad  x \geq 3.5 \\<br>                  \end{cases}<br>    $$<br>    $$    f_2(x) = f_1(x)+T_2(x) = \begin{cases}<br>                        5.72\quad x \lt 3.5 \\<br>                        6.46 \quad  3.5 \le x \lt 6.5 \\<br>                        9.13 \quad  x \ge 6.5 \\<br>                  \end{cases} $$<br>用$f_2(x)$拟合训练数据的平方损失误差是<br>$$L(y,f_2(x)) = \sum_{i=1}^{10}(y_i-f_2(x))^2=0.79$$</p>
<p>&emsp;&emsp;假设此时损失函数满足要求，则最终的提升树为<br>$$<br>f(x) = f_2(x)=<br>\begin{cases}<br>5.72\quad x \lt 3.5 \\<br>6.46 \quad  0.5 \le x \lt 6.5 \\<br>9.13 \quad  x \ge 6.5 \\<br>\end{cases}<br>$$</p>
<h1 id="xgboost"><a href="#xgboost" class="headerlink" title="xgboost"></a>xgboost</h1><p>&emsp;&emsp;xgboost的损失函数与gbdt有所不同，其形式如下<br>$$<br>    L(\Theta_m)=\sum_{i=1}^{N}L(y_i,f_{m-1}(x_i)+T(x;\Theta_m)) + \Omega(T(x;\Theta_m))+ C<br>\tag{5.1}<br>$$<br>其中$i$是指地$i$个样本，$f_{m-1}(x_i)$表示第$m-1$个模型对样本$i$的预测值，$T(x;\Theta_m)$表示第$m$个树模型，$\Omega(T(x;\Theta_m)$表示正则项，$C$表示计算过程中的一些常数项。</p>
<p>对5.1式连加部分尝试用泰勒二阶展开有<br>$$<br>    L(\Theta_m) \approx \sum_{i=1}^{N}[L(y_i,f_{m-1}(x_i)) + \frac{\partial{L(y_i,f_{m-1}(x_i))}}{\partial{L(f_{m-1}(x_i))}} \cdot T(x;\Theta_m) + \frac{1}{2} \cdot \frac{\partial^2{L(y_i,f_{m-1}(x_i))}}{\partial{L(f_{m-1}(x_i))^2}} \cdot T^2(x;\Theta_m)]+ \Omega(T(x;\Theta_m)) + C<br>\tag{5.2}<br>$$</p>
<ul>
<li>注： 泰勒二阶展开式$f(x+\Delta x)=f(x) + \frac{\partial f(x)}{\partial x} \cdot \Delta x +  \frac{\partial^2 f(x)}{\partial^2 x} \cdot \Delta^2 x$</li>
</ul>
<p>此处定义样本$i$的一阶和二阶导数为<br>$$<br>    g_i=\frac{\partial{L(y_i,f_{m-1}(x_i))}}{\partial{L(f_{m-1}(x_i))}} \\<br>    h_i=\frac{\partial^2{L(y_i,f_{m-1}(x_i))}}{\partial{L(f_{m-1}(x_i))^2}}<br>$$<br>所以5.1式可以表示为<br>$$<br>    L(\Theta_m) \approx \sum_{i=1}^{N}[L(y_i,f_{m-1}(x_i)) + g_i \cdot T(x;\Theta_m) +  \frac{1}{2} \cdot h_i \cdot T^2(x;\Theta_m)]+ \Omega(T(x;\Theta_m)) + C<br>\tag{5.3}<br>$$<br>其中$\sum_{i=1}^{N}L(y_i,f_{m-1}(x_i))$是定值可以和$C$项合并，有<br>$$<br>L(\Theta_m) \approx \sum_{i=1}^{N}[g_i \cdot T(x;\Theta_m) + \frac{1}{2} \cdot h_i \cdot T^2(x;\Theta_m)]+ \Omega(T(x;\Theta_m)) + C<br>\tag{5.4}<br>$$<br>&emsp;&emsp;决策树的正则项一般考虑的是叶子结点的个数和叶子权值，比较常见的正则项如下<br>$$<br>    \Omega(T(x;\Theta_m)) = \gamma \cdot T_t+\lambda \cdot \frac{1}{2}\sum_{j=1}^{T}w^2_j<br>$$<br>5.4式变为<br>$$<br>L(\Theta_m) \approx \sum_{i=1}^{N}[g_i \cdot T(x;\Theta_m) + \frac{1}{2} \cdot h_i \cdot T^2(x;\Theta_m)]+ \gamma \cdot T_t+\lambda \cdot \frac{1}{2}\sum_{j=1}^{T}w^2_j + C<br>\tag{5.5}<br>$$<br>&emsp;&emsp;为了进一步整合3式，对$T(x;\Theta_m)$的表达形式进行修改，$T(x;\Theta_m)$重新定义为<br>$$<br>    T(x;\Theta_m)=w_{q(x)}<br>$$<br>其中$w$是叶子结点的权重值，$q$函数表示输入$x$和叶子结点的对应关系。所以5.5式变为<br>$$<br>L(\Theta_m) \approx \sum_{i=1}^{N}[g_i \cdot w_{q(x_i)} + \frac{1}{2} \cdot h_i \cdot w^2_{q(x_i)}]+ \gamma \cdot T_t+\lambda \cdot \frac{1}{2}\sum_{j=1}^{T}w^2_{q(x_i)} + C<br>\tag{5.6}<br>$$<br>对5.6式做进一步推导，$\sum_{i=1}^{N}[g_i \cdot w_{j}(x_i)]$表示第$m$棵树的输出的乘积，这是从样本角度来看的；从树的角度来看，每个样本一定且唯一被分到其中的一个叶子结点，一个叶子结点可以分到多个样本，可以将每个叶子结点的样本梯度相加，再乘以叶子结点的权值，最后对所有叶子结点求和，所以有<br>$$<br>    \sum_{i=1}^{N}g_i \cdot w_{q(x_i)}=\sum_{j=1}^{T}(\sum_{i \in I_j}g_i)w_{mj} \\<br>    \sum_{i=1}^{N}h_i \cdot w^2_{q(x_i)}=\sum_{j=1}^{T}(\sum_{i \in I_j}h_i)w^2_{mj}<br>$$</p>
<p>把位于同一叶子上的一阶偏导和记做$G$，同一叶子上的二阶偏导和记为$H$，所以最终1式变为<br>$$<br>\begin{split}<br>L(\Theta_m) &amp;\approx \sum_{j=1}^{T}[(\sum_{i \in I_j}g_i)w_{j}+ \frac{1}{2} \cdot (\sum_{i \in I_j}h_i)w^2_{j}]+ \gamma \cdot T_t+\lambda*\frac{1}{2}\sum_{j=1}^{T}w^2_{j} + C \\<br> &amp;\approx \sum_{j=1}^{T}[G_i \cdot w_{j}+ \frac{1}{2} \cdot (\lambda+ H_i )w^2_{j}]+ \gamma \cdot T_t + C<br>\end{split}<br>\tag{5.7}<br>$$<br>5.7式对$w_mj$求偏导令其为0，有<br>$$<br>\begin{split}<br>\frac{\partial L(\Theta_m)}{\partial w_{mj}}=0 =&gt;\\<br>G_j+(H_j+\lambda)=0 =&gt;\\<br>w_{j}=-\frac{G_j}{H_j+\lambda}<br>\end{split}<br>$$<br>然后带回公式7有<br>$$<br>L(\Theta_m) \approx -\frac{1}{2}\sum_{j=1}^{T}\frac{G^2_j}{H_j+\lambda} + \gamma  \cdot  T_t<br>\tag{5.8}<br>$$<br>公式5.8就是最终的损失函数。</p>
<p>&emsp;&emsp;该损失函数怎么使用呢？其实它可以指导建树，建树的时候最关键的一步就是选择一个分裂的准则，也就如何评价分裂的质量。比如在上面GBDT的介绍里，选择MSE来评价分裂的质量。在xgboost里分裂准则直接与损失函数挂钩，具体来说是通过损失函数计算增益$Gain$<br>$$<br>    Gain=\frac{1}{2}[\frac{G^2_L}{H_L+\lambda}+\frac{G^2_R}{H_R+\lambda}-\frac{(G_L+G_R)^2}{(H_L+H_R)+\lambda}] - \gamma<br>$$<br>其中$ \frac{(G_L+G_R)^2}{(H_L+H_R)+\lambda}$表示对于一个结点，如果不分裂的话此时的损失。如果在这个节点进行分裂，则分裂后的左右子结点的损失分别为$\frac{G^2_L}{H_L+\lambda}$，$\frac{G^2_R}{H_R+\lambda}$，找到一种分裂使$Gain$最大。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>&emsp;&emsp;数据集如下，15条样本数据，2个特征：</p>
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">$x_1$</th>
<th style="text-align:center">$x_2$</th>
<th style="text-align:center">y</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">-5</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
<td style="text-align:center">5</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">3</td>
<td style="text-align:center">-2</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">2</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">6</td>
<td style="text-align:center">-5</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">7</td>
<td style="text-align:center">5</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">6</td>
<td style="text-align:center">-2</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">9</td>
<td style="text-align:center">7</td>
<td style="text-align:center">2</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">10</td>
<td style="text-align:center">6</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">11</td>
<td style="text-align:center">8</td>
<td style="text-align:center">-5</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">12</td>
<td style="text-align:center">9</td>
<td style="text-align:center">5</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">13</td>
<td style="text-align:center">10</td>
<td style="text-align:center">-2</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">14</td>
<td style="text-align:center">8</td>
<td style="text-align:center">2</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">15</td>
<td style="text-align:center">9</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
<p>参数设置：树的深度设置为3，棵树设置为2，学习率设置为0.1，两个正则参数$\lambda=1,\gamma=0$。分类问题，损失函数选择logloss。</p>
<p>&emsp;&emsp;下面计算logloss的一阶导数和二阶导数，假设预测值为$\hat{y_i}$。<br>$$<br>L(y_i,\hat{y_i})=-y_ilog(y_{i,pred}) - (1-y_i)log(1-y_{i,pred})<br>$$<br>其中$y_{i,pred}=\frac{1}{1+e^{-\hat{y_i}}}$</p>
<p>一阶导数<br>$$<br>L’(y_i,\hat{y_i})=(\frac{y_i}{y_{i,pred}}-\frac{1-y_i}{1-y_{i,pred}})y^{‘}_{i,pred}=\frac{y_i-y_{i,pred}}{y_{i,pred}(1-y_{i,pred})}*y_{i,pred}(1-y_{i,pred})=y_i-y_{i,pred}<br>$$<br>二阶导数<br>$$<br>L’’(y_i,\hat{y_i})=(y_i-y_{i,pred})’=-y_{i,pred}(1-y_{i,pred})<br>$$</p>
<p>设置初始预测值$y_{i,pred}=0.5$，举例计算$ID_1$样本的一阶二阶导数。<br>    $g_1=y_i-y_{i,pred}=0-0.5=-0.5$<br>    $h_1=-y_{i,pred}(1-y_{i,pred})=-0.5*(1-0.5)=-0.25$<br>所以有</p>
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">5</th>
<th style="text-align:center">6</th>
<th style="text-align:center">7</th>
<th style="text-align:center">8</th>
<th style="text-align:center">9</th>
<th style="text-align:center">10</th>
<th style="text-align:center">11</th>
<th style="text-align:center">12</th>
<th style="text-align:center">13</th>
<th style="text-align:center">14</th>
<th style="text-align:center">15</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$g_i$</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">-0.5</td>
</tr>
<tr>
<td style="text-align:center">$h_i$</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
</tr>
</tbody>
</table>
<p>进行结点分裂。首先看特征$x_1$，其取值为$[1,2,3,6,7,8,9,10]$，需要依次计算每个取值进行分裂的增益。</p>
<p>以取值1为划分时</p>
<p>左结点样本$I_L=[]$，右结点样$I_L=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]$</p>
<p>左结点为空，所以$G_L=0$，$H_L=0$</p>
<p>右结点一阶导数和为$G_R=\sum_{i \in I_R}g_i=-1.5$，二阶导数和为$H_R=\sum_{i \in I_R} h_i=3.75$</p>
<p>所以增益$Gain=0$。</p>
<p>以取值2为划分时</p>
<p>左结点样本$I_L=[1,4]$，右结点样$I_L=[2,3,5,6,7,8,9,10,11,12,13,14,15]$</p>
<p>左结一阶导数和为$G_L=\sum_{i \in I_L}g_i=0.5-0.5=0$，二阶导数和为$H_L=\sum_{i \in I_L} h_i=0.25+0.25=0.5$</p>
<p>右结点一阶导数和为$G_R=\sum_{i \in I_R}g_i=0.5-0.5+…+0.5-0.5=-1.5$，二阶导数和为$H_R=\sum_{i \in I_R} h_i=0.25+…+0.25=3.25$</p>
<p>所以增益为<br>$$<br>\begin{split}<br>Gain&amp;=[\frac{G^{2}_{L}}{H_{L}+\lambda}+\frac{G^{2}_{R}}{H_{R}+\lambda}-\frac{(G_{L}+G_{R})^2}{(H_{L}+H_{R})+\lambda}]\\<br>&amp;=[0+\frac{1.5^2}{(-3.25)+1}-\frac{(0+1.5)^2}{(-0.5-3.25)+1}]\\<br>&amp;=0.0557275541796<br>\end{split}<br>$$</p>
<p>所以有</p>
<table>
<thead>
<tr>
<th style="text-align:center">split_point</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">6</th>
<th style="text-align:center">7</th>
<th style="text-align:center">8</th>
<th style="text-align:center">9</th>
<th style="text-align:center">10</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$G_L$</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-1</td>
<td style="text-align:center">-1</td>
<td style="text-align:center">-1</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">$H_L$</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1.25</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2.5</td>
<td style="text-align:center">3</td>
<td style="text-align:center">3.5</td>
</tr>
<tr>
<td style="text-align:center">$G_R$</td>
<td style="text-align:center">-1.5</td>
<td style="text-align:center">-1.5</td>
<td style="text-align:center">-1</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">0.5</td>
</tr>
<tr>
<td style="text-align:center">$H_R$</td>
<td style="text-align:center">3.25</td>
<td style="text-align:center">2.75</td>
<td style="text-align:center">2.5</td>
<td style="text-align:center">1.75</td>
<td style="text-align:center">1.25</td>
<td style="text-align:center">0.75</td>
<td style="text-align:center">0.25</td>
</tr>
<tr>
<td style="text-align:center">$Gain$</td>
<td style="text-align:center">0.0557</td>
<td style="text-align:center">0.1263</td>
<td style="text-align:center">-0.0769</td>
<td style="text-align:center">-0.0494</td>
<td style="text-align:center">-0.0769</td>
<td style="text-align:center">-0.0808</td>
<td style="text-align:center">0.6152</td>
</tr>
</tbody>
</table>
<p>特征$x1$以$x1&lt;10$分裂时可以得到最大的增益0.615204678363。</p>
<p>看特征$x_2$，其取值为$[-5,-2,0,2,5]$，需要依次计算每个取值进行分裂的增益。</p>
<table>
<thead>
<tr>
<th style="text-align:center">split_point</th>
<th style="text-align:center">-2</th>
<th style="text-align:center">0</th>
<th style="text-align:center">2</th>
<th style="text-align:center">5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$G_L$</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-1.5</td>
<td style="text-align:center">-1</td>
</tr>
<tr>
<td style="text-align:center">$H_L$</td>
<td style="text-align:center">0.75</td>
<td style="text-align:center">1.5</td>
<td style="text-align:center">2.25</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">$G_R$</td>
<td style="text-align:center">-1</td>
<td style="text-align:center">-1.5</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.5</td>
</tr>
<tr>
<td style="text-align:center">$H_R$</td>
<td style="text-align:center">3</td>
<td style="text-align:center">2.25</td>
<td style="text-align:center">1.5</td>
<td style="text-align:center">0.75</td>
</tr>
<tr>
<td style="text-align:center">$Gain$</td>
<td style="text-align:center">-0.0808</td>
<td style="text-align:center">0.2186</td>
<td style="text-align:center">0.2186</td>
<td style="text-align:center">-0.0808</td>
</tr>
</tbody>
</table>
<p>以特征$x_2$分裂，最大的增益是0.218623481781，小于以$x_1$分裂的增益，所以第一次分裂以$x_1&lt;10$进行分裂。</p>
<p>由于设置的最大深度是3，此时只有1层，所以还需要继续往下分裂。 </p>
<p>左子节点的样本集合$I_L=[1,2,3,4,5,6,7,8,9,10,11,12,14,15] $</p>
<p>右子节点的样本集合$I_R=[13]$</p>
<p>右子结点只剩下一个样本，不需要再进行分裂，可以计算结点值<br>$$<br>    w=-\frac{G_R}{H_R+\lambda}=-\frac{0.5}{1+0.25}=-0.4<br>$$<br>下面对左子结点$I_L=[1,2,3,4,5,6,7,8,9,10,11,12,14,15]$进行分裂，分裂的时候把此时的结点看成根节点，同样也是需要遍历所有特征(x1,x2)的所有取值作为分裂点，选取增益最大的点。</p>
<p>遍历$x_1$</p>
<table>
<thead>
<tr>
<th style="text-align:center">split_point</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">6</th>
<th style="text-align:center">7</th>
<th style="text-align:center">8</th>
<th style="text-align:center">9</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$G_L$</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-1</td>
<td style="text-align:center">-1</td>
<td style="text-align:center">-1</td>
</tr>
<tr>
<td style="text-align:center">$H_L$</td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1.25</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2.5</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">$G_R$</td>
<td style="text-align:center">-2</td>
<td style="text-align:center">-2</td>
<td style="text-align:center">-1.5</td>
<td style="text-align:center">-1</td>
<td style="text-align:center">-1</td>
<td style="text-align:center">-1</td>
</tr>
<tr>
<td style="text-align:center">$H_R$</td>
<td style="text-align:center">3</td>
<td style="text-align:center">2.5</td>
<td style="text-align:center">2.25</td>
<td style="text-align:center">1.5</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0.5</td>
</tr>
<tr>
<td style="text-align:center">$Gain$</td>
<td style="text-align:center">0.1111</td>
<td style="text-align:center">0.2540</td>
<td style="text-align:center">-0.0855</td>
<td style="text-align:center">-0.1556</td>
<td style="text-align:center">-0.1032</td>
<td style="text-align:center">0.0278</td>
</tr>
</tbody>
</table>
<p>可以发现$x_1$在$x&lt;3$时能取得最大增益0.253968253968。</p>
<p>遍历$x_2$</p>
<table>
<thead>
<tr>
<th style="text-align:center">split_point</th>
<th style="text-align:center">-2</th>
<th style="text-align:center">0</th>
<th style="text-align:center">2</th>
<th style="text-align:center">5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$G_L$</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-0.5</td>
<td style="text-align:center">-2</td>
<td style="text-align:center">-1.5</td>
</tr>
<tr>
<td style="text-align:center">$H_L$</td>
<td style="text-align:center">0.75</td>
<td style="text-align:center">1.25</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2.75</td>
</tr>
<tr>
<td style="text-align:center">$G_R$</td>
<td style="text-align:center">-1.5</td>
<td style="text-align:center">-1.5</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.5</td>
</tr>
<tr>
<td style="text-align:center">$H_R$</td>
<td style="text-align:center">2.75</td>
<td style="text-align:center">2.25</td>
<td style="text-align:center">1.5</td>
<td style="text-align:center">0.75</td>
</tr>
<tr>
<td style="text-align:center">$Gain$</td>
<td style="text-align:center">-0.1460</td>
<td style="text-align:center">-0.0855</td>
<td style="text-align:center">0.4444</td>
<td style="text-align:center">-0.1460</td>
</tr>
</tbody>
</table>
<p>可以发现$x_2$在$x&lt;2$时能取得最大增益0.4444。</p>
<p>综上本次分裂应该选择$x&lt;2$作为分裂点，分裂后左右子结点集合如下</p>
<p>左子节点的样本集合$I_L=[1,3,5,6,8,10,11,15] $</p>
<p>右子节点的样本集合$I_R=[2,4,7,9,12,14]$</p>
<p>到此为止，第一棵树构建完毕，下面给出表达形式。根据加法模型，第一棵树的预测结果应该为<br>$$y=f_0(x_i)+f_1(x_i)$$<br>其中$f_0(x_i)$是初始值，可以看成第0棵树。在第1步中，我们假设初始值$y_{i,pred}$=0.5，由于使用logloss损失函数，所以其原始输出需要进行一个sigmoid的反变换$f_0=ln(\frac{0.5}{1-0.5})=0$，所以第一棵树的预测结果就是<br>$$y=f_0(x_i)+f_1(x_i)=0+w_{q(x_i)}=w_{q(x_i)}$$<br>第一棵树的结构如下图</p>
<div align="center"><br><img src="/从决策树到xgboost/tree_0.png" alt="第一棵树结构" width="600" height="350"><br></div>

<p>&emsp;&emsp;建立第2棵树，整个过程和第1棵树一样，但是需要更新$y_{i,pred}$，也就是说在第一棵树的基础上进行第二棵树的构建，这里的思想和GBDT一致。</p>
<p>&emsp;&emsp;以ID=1样本为例，更新$y_{i,pred}$。对于ID=1经过第一棵树，落在-0.04结点，经过sigmoid映射后的值为$p_{1,pred}=\frac{1}{1+e^{0.04}}=0.490001$，所以有</p>
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">5</th>
<th style="text-align:center">6</th>
<th style="text-align:center">7</th>
<th style="text-align:center">8</th>
<th style="text-align:center">9</th>
<th style="text-align:center">10</th>
<th style="text-align:center">11</th>
<th style="text-align:center">12</th>
<th style="text-align:center">13</th>
<th style="text-align:center">14</th>
<th style="text-align:center">15</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$y_{i,pred}$</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">0.52</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">0.52</td>
<td style="text-align:center">0.52</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">0.52</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">0.52</td>
<td style="text-align:center">0.52</td>
<td style="text-align:center">0.51</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">0.52</td>
</tr>
<tr>
<td style="text-align:center">$g_i$</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">-0.48</td>
<td style="text-align:center">-0.51</td>
<td style="text-align:center">-0.48</td>
<td style="text-align:center">-0.48</td>
<td style="text-align:center">-0.51</td>
<td style="text-align:center">0.52</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">-0.48</td>
<td style="text-align:center">-0.48</td>
<td style="text-align:center">-0.49</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">0.49</td>
<td style="text-align:center">-0.48</td>
</tr>
<tr>
<td style="text-align:center">$h_i$</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
<td style="text-align:center">0.25</td>
</tr>
</tbody>
</table>
<p>根据上表可推导出第二棵树的结构如下图</p>
<div align="center"><br>    <img src="/从决策树到xgboost/tree_1.png" alt="第二棵树结构" width="660" height="350"><br></div>


<ul>
<li>注： 由于hexo排版问题，表格中的数据进行了截位处理，可能精度不够，可以使用下面的程序进行计算。</li>
</ul>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>&emsp;&emsp;针对上面的例子，简单实现了xgboost的求解过程，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pygraphviz <span class="keyword">as</span> pgv</span><br><span class="line"><span class="keyword">from</span> TreeNode <span class="keyword">import</span> TreeNode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择最佳切分点</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestSplit</span><span class="params">(dataMat, hi, gi, r, T=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 获取特征数量</span></span><br><span class="line">    featNum = dataMat.shape[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">    <span class="comment"># 最大增益</span></span><br><span class="line">    max_gain = float(<span class="string">"-inf"</span>)</span><br><span class="line">    <span class="comment"># 切分特征下标</span></span><br><span class="line">    split_feat = <span class="number">-1</span></span><br><span class="line">    <span class="comment"># 切分点的值</span></span><br><span class="line">    split_value = <span class="number">-1</span></span><br><span class="line">    <span class="comment"># 切分后左子树的一阶导数和</span></span><br><span class="line">    split_g_l = <span class="number">-1</span></span><br><span class="line">    <span class="comment"># 切分后右子树的一阶导数和</span></span><br><span class="line">    split_g_r = <span class="number">-1</span></span><br><span class="line">    <span class="comment"># 切分后左子树的二阶导数和</span></span><br><span class="line">    split_h_l = <span class="number">-1</span></span><br><span class="line">    <span class="comment"># 切分后右子树的二阶导数和</span></span><br><span class="line">    split_h_r = <span class="number">-1</span></span><br><span class="line">    <span class="comment"># 遍历特征</span></span><br><span class="line">    <span class="keyword">for</span> feat <span class="keyword">in</span> range(featNum):</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'&#123;&#125;th feature'</span>.format(feat)</span><br><span class="line">        featList = dataMat[:, feat].T.tolist()[<span class="number">0</span>]</span><br><span class="line">        uniqueVals = sorted(set(featList))</span><br><span class="line">        <span class="comment"># 遍历特征值</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">            <span class="comment"># 挑选比特征值小的样本，即左子树样本</span></span><br><span class="line">            left_points = np.where(dataMat[:, feat] &lt; value)</span><br><span class="line">            <span class="comment"># 挑选比特征值大的样本，即右子树样本</span></span><br><span class="line">            right_points = np.where(dataMat[:, feat] &gt;= value)</span><br><span class="line">            <span class="comment"># 左子树一阶导数和</span></span><br><span class="line">            g_l = G(left_points, gi)</span><br><span class="line">            <span class="comment"># 右子树一阶导数和</span></span><br><span class="line">            g_r = G(right_points, gi)</span><br><span class="line">            <span class="comment"># 左子树二阶导数和</span></span><br><span class="line">            h_l = H(left_points, hi)</span><br><span class="line">            <span class="comment"># 右子树二阶导数和</span></span><br><span class="line">            h_r = H(right_points, hi)</span><br><span class="line">            <span class="comment"># 计算分裂增益</span></span><br><span class="line">            g = gain(g_l, h_l, g_r, h_r, r)</span><br><span class="line">            <span class="keyword">print</span> <span class="string">'&#123;&#125;-g_l:&#123;&#125;, h_l:&#123;&#125;, g_r:&#123;&#125;, h_r:&#123;&#125;-g:&#123;&#125;'</span>.format(value, g_l, h_l, g_r, h_r, g)</span><br><span class="line">            <span class="keyword">if</span> g &gt;= max_gain:</span><br><span class="line">                max_gain = g</span><br><span class="line">                split_feat = feat</span><br><span class="line">                split_value = value</span><br><span class="line">                split_g_l = g_l</span><br><span class="line">                split_g_r = g_r</span><br><span class="line">                split_h_l = h_l</span><br><span class="line">                split_h_r = h_r</span><br><span class="line">    <span class="keyword">return</span> split_feat, split_value, split_g_l, split_g_r, split_h_l, split_h_r</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行分裂</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binSplitDataSet</span><span class="params">(dataMat, split_feat, split_value, hi, gi)</span>:</span></span><br><span class="line">    left_points = np.where(dataMat[:, split_feat] &lt; split_value)</span><br><span class="line">    right_points = np.where(dataMat[:, split_feat] &gt;= split_value)</span><br><span class="line">    <span class="keyword">return</span> dataMat[left_points[<span class="number">0</span>]], dataMat[right_points[<span class="number">0</span>]], hi[left_points[<span class="number">0</span>]], hi[right_points[<span class="number">0</span>]], gi[</span><br><span class="line">        left_points[<span class="number">0</span>]], gi[right_points[<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataMat, hi, gi, depth=<span class="number">0</span>, max_depth=<span class="number">3</span>, r=<span class="number">1</span>, eta=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 选择最佳切分特征、最佳切分点、左右子树的一阶二阶导数和</span></span><br><span class="line">    feat, val, g_l, g_r, h_l, h_r = chooseBestSplit(dataMat, hi, gi, r)</span><br><span class="line">    root = TreeNode(feat, val)</span><br><span class="line">    <span class="comment"># 结点分裂，返回左右子结点每个样本的一阶导数和二阶导数值</span></span><br><span class="line">    lSet, rSet, hi_l, hi_r, gi_l, gi_r = binSplitDataSet(dataMat, feat, val, hi, gi)</span><br><span class="line">    <span class="comment"># 如果数据集中样本个数大于1并且树的深度小于3层</span></span><br><span class="line">    <span class="keyword">if</span> len(set(lSet[:, <span class="number">-1</span>].T.tolist()[<span class="number">0</span>])) &gt; <span class="number">1</span> <span class="keyword">and</span> depth + <span class="number">1</span> &lt; max_depth:</span><br><span class="line">        root.left = createTree(lSet, hi_l, gi_l, depth + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        leaf = TreeNode(<span class="number">-1</span>, <span class="number">-1</span>)</span><br><span class="line">        leaf.weight = eta * cal_weight(g_l, h_l, r)</span><br><span class="line">        leaf.isLeaf = <span class="keyword">True</span></span><br><span class="line">        root.left = leaf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(set(rSet[:, <span class="number">-1</span>].T.tolist()[<span class="number">0</span>])) &gt; <span class="number">1</span> <span class="keyword">and</span> depth + <span class="number">1</span> &lt; max_depth:</span><br><span class="line">        root.right = createTree(rSet, hi_r, gi_r, depth + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        leaf = TreeNode(<span class="number">-1</span>, <span class="number">-1</span>)</span><br><span class="line">        leaf.weight = eta * cal_weight(g_r, h_r, r)</span><br><span class="line">        leaf.isLeaf = <span class="keyword">True</span></span><br><span class="line">        root.right = leaf</span><br><span class="line">    <span class="keyword">return</span> root</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算叶子结点权重</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_weight</span><span class="params">(g, h, r)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> -g / (h + r)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算一阶导数和</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">G</span><span class="params">(points, hi)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.sum(hi[points])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算二阶导数和</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">H</span><span class="params">(points, gi)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.sum(gi[points])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算增益</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gain</span><span class="params">(g_l, h_l, g_r, h_r, r)</span>:</span></span><br><span class="line">    left_gain = math.pow(g_l, <span class="number">2</span>) / (h_l + r)</span><br><span class="line">    right_gain = math.pow(g_r, <span class="number">2</span>) / (h_r + r)</span><br><span class="line">    all_gain = math.pow(g_l + g_r, <span class="number">2</span>) / (h_l + h_r + r)</span><br><span class="line">    <span class="keyword">return</span> left_gain + right_gain - all_gain</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个样本的一阶导数值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">g_i</span><span class="params">(y_pred, y_i)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> y_pred - y_i</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个样本的二阶导数值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">h_i</span><span class="params">(y_pred)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> y_pred * (<span class="number">1</span> - y_pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(path)</span>:</span></span><br><span class="line">    data = pd.read_csv(path, dtype=np.float64, delimiter=<span class="string">'\t'</span>, header=<span class="keyword">None</span>)</span><br><span class="line">    dataMat = np.mat(data.values)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化一阶导数和二阶导数值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_base_score</span><span class="params">(trees, dataMat)</span>:</span></span><br><span class="line">    label = dataMat[:, <span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">if</span> len(trees) == <span class="number">0</span>:</span><br><span class="line">        base_score = np.zeros((dataMat.shape[<span class="number">0</span>], <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># 初始值设置为0.5，即base_score</span></span><br><span class="line">        base_score += <span class="number">0.5</span></span><br><span class="line">        gi = g_i(base_score, label)</span><br><span class="line">        hi = h_i(base_score)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 上一次预测值</span></span><br><span class="line">        pred_res = predict(trees, dataMat)</span><br><span class="line">        gi = g_i(pred_res, label)</span><br><span class="line">        hi = h_i(pred_res)</span><br><span class="line">    <span class="keyword">return</span> hi, gi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(trees, dataMat)</span>:</span></span><br><span class="line">    pred_res = np.zeros((dataMat.shape[<span class="number">0</span>], <span class="number">1</span>), dtype=np.float64)</span><br><span class="line">    <span class="keyword">for</span> tree <span class="keyword">in</span> trees:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(dataMat.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="comment"># 获取输入数据在每棵树上的输出</span></span><br><span class="line">            weight = tree.get_weight(dataMat[i, :])</span><br><span class="line">            <span class="comment"># sigmoid变换</span></span><br><span class="line">            pred_res[i, <span class="number">0</span>] += <span class="number">1</span> / (<span class="number">1</span> + math.exp(-weight))</span><br><span class="line">    <span class="keyword">return</span> pred_res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 画图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_tree</span><span class="params">(root, i)</span>:</span></span><br><span class="line">    A = pgv.AGraph(directed=<span class="keyword">True</span>, strict=<span class="keyword">True</span>)</span><br><span class="line">    display(root, A)</span><br><span class="line">    A.graph_attr[<span class="string">'epsilon'</span>] = <span class="string">'0.01'</span></span><br><span class="line">    <span class="keyword">print</span> A.string()  <span class="comment"># print dot file to standard output</span></span><br><span class="line">    A.write(<span class="string">'tree_&#123;&#125;.dot'</span>.format(i))</span><br><span class="line">    A.layout(<span class="string">'dot'</span>)  <span class="comment"># layout with dot</span></span><br><span class="line">    A.draw(<span class="string">'tree_&#123;&#125;.png'</span>.format(i))  <span class="comment"># write to file</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">display</span><span class="params">(root, A)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    A.add_node(root.uid, label=<span class="string">'x[&#123;&#125;]&lt;&#123;&#125;'</span>.format(root.split_feat, root.split_value))</span><br><span class="line">    <span class="keyword">if</span> root.left:</span><br><span class="line">        <span class="keyword">if</span> root.left.isLeaf:</span><br><span class="line">            A.add_node(root.left.uid, label=<span class="string">'leaf=&#123;&#125;'</span>.format(root.left.weight))</span><br><span class="line">            A.add_edge(root.uid, root.left.uid, label=<span class="string">'yes'</span>, color=<span class="string">'red'</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            A.add_node(root.left.uid, label=<span class="string">'x[&#123;&#125;]&lt;&#123;&#125;'</span>.format(root.left.split_feat, root.left.split_value))</span><br><span class="line">            A.add_edge(root.uid, root.left.uid, label=<span class="string">'yes'</span>, color=<span class="string">'red'</span>)</span><br><span class="line">            display(root.left, A)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> root.right:</span><br><span class="line">        <span class="keyword">if</span> root.right.isLeaf:</span><br><span class="line">            A.add_node(root.right.uid, label=<span class="string">'leaf=&#123;&#125;'</span>.format(root.right.weight))</span><br><span class="line">            A.add_edge(root.uid, root.right.uid, label=<span class="string">'no'</span>, color=<span class="string">'blue'</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            A.add_node(root.right.uid, label=<span class="string">'x[&#123;&#125;]&lt;&#123;&#125;'</span>.format(root.right.split_feat, root.right.split_value))</span><br><span class="line">            A.add_edge(root.uid, root.right.uid, label=<span class="string">'no'</span>, color=<span class="string">'blue'</span>)</span><br><span class="line">            display(root.right, A)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    dataMat = load_data(<span class="string">'./data.txt'</span>)</span><br><span class="line">    root = <span class="keyword">None</span></span><br><span class="line">    trees = []</span><br><span class="line">    tree_num = <span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(tree_num):</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'&#123;&#125;th tree building'</span>.format(i)</span><br><span class="line">        hi, gi = init_base_score(trees, dataMat)</span><br><span class="line">        root = createTree(dataMat, hi, gi)</span><br><span class="line">        trees.append(root)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(trees)):</span><br><span class="line">        <span class="keyword">print</span> trees[i]</span><br><span class="line">        draw_tree(trees[i], i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>代码详见<a href="https://github.com/yajian/machine_learning/tree/master/tree/xgboost" target="_blank" rel="noopener">xgboost简单实现</a></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li>机器学习实战，人民邮电出版社</li>
<li>统计学习方法，清华大学出版社</li>
<li><a href="https://blog.csdn.net/qq_22238533/article/details/79477547" target="_blank" rel="noopener">xgboost原理分析以及实践</a></li>
<li><a href="https://xgboost.readthedocs.io/en/latest/tutorials/model.html" target="_blank" rel="noopener">XGBoost Documentation</a></li>
</ol>

          
        
      
    </div>
    
    
    



    

    <div>
      
    </div>

    <div>
      
    </div>

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yajian.github.io/CART-分类与回归树/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小建儿">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小建儿的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/CART-分类与回归树/" itemprop="url">CART-分类与回归树</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-13T10:32:10+08:00">
                2018-12-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/CART-分类与回归树/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="CART-分类与回归树/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;分类与回归树(classification and regression tree, CART)模型是应用比较广泛的决策树学习方法之一，它既可以用于分类也可以用于回归。CART算法使用二元切分递归地处理每个特征，如果特征值大于给定值就走左子树，否则就走右子树。</p>
<h1 id="最小二乘回归树生成算法"><a href="#最小二乘回归树生成算法" class="headerlink" title="最小二乘回归树生成算法"></a>最小二乘回归树生成算法</h1><h2 id="数学描述"><a href="#数学描述" class="headerlink" title="数学描述"></a>数学描述</h2><p>&emsp;&emsp;假设$X$和$Y$分别为输入和输出变量，并且$Y$是连续变量，给定训练数据集<br>$$D={(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$$<br>生成对应的回归树。</p>
<p>&emsp;&emsp;一个回归树对应着输入空间(即特征空间)的一个划分以及在划分的单元上的输出值。假设已将输入空间划分为$M$个单元$R_1,R_2,…,R_m$，并且在每个单元$R_m$上有一个固定的输出值$C_m$，于是回归树模型可以表示为</p>
<p>$$f(x) = \sum_{m=1}^{M}c_mI(x \in R_m)$$</p>
<p>其中函数$I$为指示函数。</p>
<p>&emsp;&emsp;当输入空间的划分确定时，可以用平方误差$\sum_{x_i \in R_m}(y_i-f(x_i))^2$来表示回归树对于训练数据的预测误差。用平方误差最小的准则求解每个单元上的最优输出值，可以发现单元$R_m$上的最优$\hat c_m$是$R_m$上所有示例$x_i$对应的输出$y_i$的均值，即<br>$$\hat c_m=avg(y_i|x_i \in R_m)$$</p>
<p>&emsp;&emsp;上面内容讲述了在输入空间划分确定的情况下，如何衡量决策树的效果以及在效果最好的情况下反推每个区域输出值$c_m$。接下来我们来看如何划分输入空间。</p>
<p>&emsp;&emsp;首先，CART树是一棵二叉树，所以我们需要选择一个特征$x^{(j)}$和它的取值$s$，作为整个数据集的切分量和切分点，并定义由其切分的两个区域<br>$$R_1(j,s)=\lbrace x|x^{(j)} \leq s \rbrace和R_2(j,s)=\lbrace x|x^{(j)} \gt s \rbrace $$<br>然后寻找最优缺切分变量$j$和最优切分点$s$，即求解</p>
<p>$$min_{j,s}[min_{c1}\sum_{x_i \in R_1(j,s)}(y_i-c_1)^2+min_{c2}\sum_{x_i \in R_2(j,s)}(y_i-c_2)^2]$$</p>
<ul>
<li>注：这里是要找到使$R_1$数据的预测误差最小的$c_1$和使$R_2$数据的预测误差最小的$c_2$，之前说过使误差最小的取值就是分别取两个数据集的均值，然后还要保证$R_1$和$R_2$误差和最小。</li>
</ul>
<p>对于固定的输入变量$j$可以找到最优的切分点$s$：</p>
<p>$$\hat c_1=avg(y_i|x_i \in R_1(j,s)) 和 \hat c_2=avg(y_i|x_i \in R_2(j,s))$$</p>
<ul>
<li>注：简单讲，这里的$c_1$和$c_2$是每次按照切分点$s$分割成两波数据的均值，这里不明白的可以看后面的例子。</li>
</ul>
<p>&emsp;&emsp;遍历所有输入变量，找到最优的切分变量$j$，构成一对$(j,s)$，并依此将输入空间划分为两个区域。接着对每个区域重复上述划分过程，直到满足条件为止。这样就生成了一棵回归树，这样的回归树通常称为最小二乘回归树。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>&emsp;&emsp;上述数学描述比较晦涩，举个简单的例子，输入数据见下表</p>
<table>
<thead>
<tr>
<th style="text-align:center">x</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">5</th>
<th style="text-align:center">6</th>
<th style="text-align:center">7</th>
<th style="text-align:center">8</th>
<th style="text-align:center">9</th>
<th style="text-align:center">10</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">y</td>
<td style="text-align:center">5.56</td>
<td style="text-align:center">5.7</td>
<td style="text-align:center">5.91</td>
<td style="text-align:center">6.4</td>
<td style="text-align:center">6.8</td>
<td style="text-align:center">7.05</td>
<td style="text-align:center">8.9</td>
<td style="text-align:center">8.7</td>
<td style="text-align:center">9</td>
<td style="text-align:center">9.05</td>
</tr>
</tbody>
</table>
<ul>
<li>第一次划分</li>
</ul>
<p>&emsp;&emsp;由于只有$x$一个变量，因此最优切分变量为$x$。接下来假设9个切分点为$[1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5]$，计算每个切分点的输出值。如$s=1.5$时，$R_1={1},R_2={2,3,4,5,6,7,8,9,10}$，这两个区域的输出值分别为$c_1=5.56,c_2=\frac{1}{9}(5.7+5.91+6.4+6.8+7.05+8.9+8.7+9+9.05)=7.50$，所以有</p>
<table>
<thead>
<tr>
<th style="text-align:center">s</th>
<th style="text-align:center">1.5</th>
<th style="text-align:center">2.5</th>
<th style="text-align:center">3.5</th>
<th style="text-align:center">4.5</th>
<th style="text-align:center">5.5</th>
<th style="text-align:center">6.5</th>
<th style="text-align:center">7.5</th>
<th style="text-align:center">8.5</th>
<th style="text-align:center">9.5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$c_1$</td>
<td style="text-align:center">5.56</td>
<td style="text-align:center">5.63</td>
<td style="text-align:center">5.72</td>
<td style="text-align:center">5.89</td>
<td style="text-align:center">6.07</td>
<td style="text-align:center">6.24</td>
<td style="text-align:center">6.62</td>
<td style="text-align:center">6.88</td>
<td style="text-align:center">7.11</td>
</tr>
<tr>
<td style="text-align:center">$c_2$</td>
<td style="text-align:center">7.5</td>
<td style="text-align:center">7.73</td>
<td style="text-align:center">7.99</td>
<td style="text-align:center">8.25</td>
<td style="text-align:center">8.54</td>
<td style="text-align:center">8.91</td>
<td style="text-align:center">8.92</td>
<td style="text-align:center">9.03</td>
<td style="text-align:center">9.05</td>
</tr>
</tbody>
</table>
<p>接下来计算每个切分点的误差，如$s=1.5$时，$loss(s=1.5)=\frac{1}{2}(5.56-5.56)^2+\sum_{i=2}^{10}\frac{1}{2}(y_i-7.5)^2=0+15.72=15.72$，所以有</p>
<table>
<thead>
<tr>
<th style="text-align:center">s</th>
<th style="text-align:center">1.5</th>
<th style="text-align:center">2.5</th>
<th style="text-align:center">3.5</th>
<th style="text-align:center">4.5</th>
<th style="text-align:center">5.5</th>
<th style="text-align:center">6.5</th>
<th style="text-align:center">7.5</th>
<th style="text-align:center">8.5</th>
<th style="text-align:center">9.5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$loss(s)$</td>
<td style="text-align:center">15.72</td>
<td style="text-align:center">12.07</td>
<td style="text-align:center">8.36</td>
<td style="text-align:center">5.78</td>
<td style="text-align:center">3.91</td>
<td style="text-align:center">1.93</td>
<td style="text-align:center">8.01</td>
<td style="text-align:center">11.73</td>
<td style="text-align:center">15.74</td>
</tr>
</tbody>
</table>
<p>其中当$s=6.5$时，$loss(s)$最小，因此第一个划分变量是$j=x,s=6.5$。</p>
<p>$$<br>T=\begin{cases}<br>6.24 \quad x \le 6.5 \\<br>8.91 \quad x \gt 6.5\\<br>\end{cases}<br>$$</p>
<ul>
<li><p>第二次划分</p>
<p>  &emsp;&emsp;第一个划分变量将数据集划分成了两部分即$R_1={1,2,3,4,5,6},R_2={7,8,9,10}$，接下来分别在$R_1,R_2$上进行划分。</p>
<ul>
<li>&emsp;&emsp;对于$R_1$</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">x</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">5</th>
<th style="text-align:center">6</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">y</td>
<td style="text-align:center">5.56</td>
<td style="text-align:center">5.7</td>
<td style="text-align:center">5.91</td>
<td style="text-align:center">6.4</td>
<td style="text-align:center">6.8</td>
<td style="text-align:center">7.05</td>
</tr>
</tbody>
</table>
<p>&emsp;&emsp;取切分点$[1.5,2.5,3.5,4.5,5.5]$，对应的输出值为</p>
<table>
<thead>
<tr>
<th style="text-align:center">s</th>
<th style="text-align:center">1.5</th>
<th style="text-align:center">2.5</th>
<th style="text-align:center">3.5</th>
<th style="text-align:center">4.5</th>
<th style="text-align:center">5.5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$c_1$</td>
<td style="text-align:center">5.56</td>
<td style="text-align:center">5.63</td>
<td style="text-align:center">5.72</td>
<td style="text-align:center">5.89</td>
<td style="text-align:center">6.07</td>
</tr>
<tr>
<td style="text-align:center">$c_2$</td>
<td style="text-align:center">6.37</td>
<td style="text-align:center">6.54</td>
<td style="text-align:center">6.75</td>
<td style="text-align:center">6.93</td>
<td style="text-align:center">7.05</td>
</tr>
</tbody>
</table>
<p>&emsp;&emsp;误差为</p>
<table>
<thead>
<tr>
<th style="text-align:center">s</th>
<th style="text-align:center">1.5</th>
<th style="text-align:center">2.5</th>
<th style="text-align:center">3.5</th>
<th style="text-align:center">4.5</th>
<th style="text-align:center">5.5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$loss(s)$</td>
<td style="text-align:center">1.3087</td>
<td style="text-align:center">0.754</td>
<td style="text-align:center">0.2771</td>
<td style="text-align:center">0.4368</td>
<td style="text-align:center">1.0644</td>
</tr>
</tbody>
</table>
<p>所以$s=3.5$时，$loss(s)$最小</p>
<p>&emsp;&emsp;假设在生成3个区域后停止划分，那么最终生成的回归树如下：</p>
<p>$$<br>T=\begin{cases}<br>5.72 \quad x \le 3.5 \\<br>6.75 \quad 3.5 \lt x \leq 6.5 \\<br>8.91 \quad x \gt 6.5\\<br>\end{cases}<br>$$</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(path)</span>:</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = open(path, <span class="string">'rb'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        fltLine = map(float, currLine)</span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> mat(dataMat)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以value为分界点切分数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binSplitDataSet</span><span class="params">(dataSet, feature, value)</span>:</span></span><br><span class="line">    mat0 = dataSet[nonzero(dataSet[:, feature] &gt; value)[<span class="number">0</span>], :]</span><br><span class="line">    mat1 = dataSet[nonzero(dataSet[:, feature] &lt;= value)[<span class="number">0</span>], :]</span><br><span class="line">    <span class="keyword">return</span> mat0, mat1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算叶子结点中数据的均值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">regLeaf</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> mean(dataSet[:, <span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算误差，即数据集的平方误差，这里使用方差乘以总个数计算</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">regErr</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> var(dataSet[:, <span class="number">-1</span>]) * shape(dataSet)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 二元切分选择分裂点</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestSplit</span><span class="params">(dataSet, leafType=regLeaf, errType=regErr, ops=<span class="params">(<span class="number">1</span>, <span class="number">4</span>)</span>)</span>:</span></span><br><span class="line">    tolS = ops[<span class="number">0</span>]</span><br><span class="line">    tolN = ops[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> len(set(dataSet[:, <span class="number">-1</span>].T.tolist()[<span class="number">0</span>])) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span>, leafType(dataSet)</span><br><span class="line">    m, n = shape(dataSet)</span><br><span class="line">    S = errType(dataSet)</span><br><span class="line">    bestS = inf</span><br><span class="line">    bestIndex = <span class="number">0</span></span><br><span class="line">    bestValue = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> featIndex <span class="keyword">in</span> range(n - <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> splitVal <span class="keyword">in</span> set(dataSet[:, featIndex].T.tolist()[<span class="number">0</span>]):</span><br><span class="line">            <span class="comment"># 切分数据集</span></span><br><span class="line">            mat0, mat1 = binSplitDataSet(dataSet, featIndex, splitVal)</span><br><span class="line">            <span class="comment"># 判断切分后的数据集的条数是否满足要求</span></span><br><span class="line">            <span class="keyword">if</span> (shape(mat0)[<span class="number">0</span>] &lt; tolN) <span class="keyword">or</span> (shape(mat1)[<span class="number">0</span>] &lt; tolN):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 计算两个数据集的误差</span></span><br><span class="line">            newS = errType(mat0) + errType(mat1)</span><br><span class="line">            <span class="comment"># 选取误差最小的切分方式</span></span><br><span class="line">            <span class="keyword">if</span> newS &lt; S:</span><br><span class="line">                bestIndex = featIndex</span><br><span class="line">                bestValue = splitVal</span><br><span class="line">                bestS = newS</span><br><span class="line">    <span class="comment"># 如果误差已经小于要求的误差</span></span><br><span class="line">    <span class="keyword">if</span> S - bestS &lt; tolS:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span>, leafType(dataSet)</span><br><span class="line">    mat0, mat1 = binSplitDataSet(dataSet, bestIndex, bestValue)</span><br><span class="line">    <span class="comment"># 如果不满足条数要求，不再继续分裂，返回结点的值</span></span><br><span class="line">    <span class="keyword">if</span> (shape(mat0)[<span class="number">0</span>] &lt; tolN) <span class="keyword">or</span> (shape(mat1)[<span class="number">0</span>] &lt; tolN):</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span>, leafType(dataSet)</span><br><span class="line">    <span class="keyword">return</span> bestIndex, bestValue</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, leafType=regLeaf, errType=regErr, ops=<span class="params">(<span class="number">1</span>, <span class="number">4</span>)</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 选择最佳分裂点</span></span><br><span class="line">    feat, val = chooseBestSplit(dataSet, leafType, errType, ops)</span><br><span class="line">    <span class="keyword">if</span> feat == <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> val</span><br><span class="line">    retTree = &#123;&#125;</span><br><span class="line">    retTree[<span class="string">'spInd'</span>] = feat</span><br><span class="line">    retTree[<span class="string">'spVal'</span>] = val</span><br><span class="line">    lSet, rSet = binSplitDataSet(dataSet, feat, val)</span><br><span class="line">    <span class="comment"># 左子树</span></span><br><span class="line">    retTree[<span class="string">'left'</span>] = createTree(lSet, leafType, errType, ops)</span><br><span class="line">    <span class="comment"># 柚子树</span></span><br><span class="line">    retTree[<span class="string">'right'</span>] = createTree(rSet, leafType, errType, ops)</span><br><span class="line">    <span class="keyword">return</span> retTree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    data = loadDataSet(<span class="string">'./data.txt'</span>)</span><br><span class="line">    tree = createTree(data)</span><br><span class="line">    <span class="keyword">print</span> tree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>代码详见<a href="https://github.com/yajian/machine_learning/blob/master/tree/cart/regTrees.py" target="_blank" rel="noopener">CART</a></p>
<ul>
<li>注：此处代码参考《机器学习实战》p161-p164，原书代码中存在错误，这里进行了修改。</li>
</ul>
<h1 id="分类树生成算法"><a href="#分类树生成算法" class="headerlink" title="分类树生成算法"></a>分类树生成算法</h1><p>&emsp;&emsp;分类树使用基尼指数选择最优特征，同时决定最优二值切分点。</p>
<h2 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h2><p>&emsp;&emsp;基尼指数的定义如下，假设有$K$个分类，样本点属于第$k$类的概率为$p_k$，则概率分布的基尼指数为<br>$$<br>    Gini(p) = \sum_{k=1}^{K}p_k(1-p_k)=1-\sum_{k=1}^{K}p^2_k<br>$$</p>
<p>&emsp;&emsp;对于给定的样本集合$D$，其基尼指数为<br>$$<br>    Gini(D)=1-\sum_{i=1}^{K}(\frac{|C_k|}{|D|})^2<br>$$<br>其中，$C_k$是$D$中属于第$k$类的样本子集，$K$是类的个数。</p>
<p>&emsp;&emsp;如果样本集合$D$根据特征$A$是否取某一可能值$a$呗分割成$D_1$和$D_2$两部分，即<br>$$<br>    D_1 = {(x,y) \in D|A(x)=a}\\<br>    D_2 = D-D_1<br>$$<br>则在特征$A$的条件下，集合$D$的基尼指数定义为<br>$$<br>    Gini(D,A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)<br>$$<br>基尼指数$Gini(D)$表示集合$D$的不确定性，基尼指数$Gini(D,A)$表示经$A=a$分割后集合$D$的不确定性。基尼指数越大，样本集合的不确定性也就越大，这一点和熵一致。</p>
<ul>
<li>注：CART分类树为什么要使用基尼指数作为选择最优特征的标准呢？因为基尼指数不仅拥有与熵类似的性质，而且计算简便，不用使用log函数。</li>
</ul>
<h2 id="生成算法"><a href="#生成算法" class="headerlink" title="生成算法"></a>生成算法</h2><p>&emsp;&emsp;输入：训练数据集$D$，停止计算的条件；</p>
<p>&emsp;&emsp;输出：CART决策树</p>
<p>&emsp;&emsp;根据训练数据集，从根节点开始，递归地对每个结点进行以下操作，构建二叉决策树</p>
<ol>
<li>设结点的训练数据集为$D$，计算现有特征对该数据集的基尼指数。此时对每个特征$A$，对其可能取值的每个值$a$，根据样本点对$A=a$的测试为“是”或”否“将$D$分割成$D_1$和$D_2$两部分，并计算$A=a$的基尼指数。</li>
<li>在所有可能的特征$A$以及它们所有可能的切分点$a$中，选择基尼指数最小的特征及其对应的切分点作为最优特征和最优切分点。依最优特征与最优切分点，从现结点生成两个子结点，将训练数据依特征分配到两个子结点中。</li>
<li>对两个子结点递归地调用1、2，直至满足停止条件</li>
<li>生成CART决策树</li>
</ol>
<p>&emsp;&emsp;算法停止条件是结点中的样本个数小于预定阈值，或者样本集的基尼指数小于预定阈值（样本基本属于同一类），或者没有更多特征。</p>
<h2 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h2><p>&emsp;&emsp;数据集合如下:</p>
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">年龄</th>
<th style="text-align:center">有工作</th>
<th style="text-align:center">有自己的房子</th>
<th style="text-align:center">信贷情况</th>
<th style="text-align:center">类别</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">好</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
<td style="text-align:center">好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">好</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">9</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">非常好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">10</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">非常好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">11</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">非常好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">12</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">13</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
<td style="text-align:center">好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">14</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
<td style="text-align:center">非常好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">15</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
<p>&emsp;&emsp;分别以$A_1$、$A_2$、$A_3$、$A_4$表示年龄、有工作、有自己的房子和信贷4个特征。</p>
<p>&emsp;&emsp;求特征$A_1$的基尼指数，以1，2，3表示年龄的值为青年、中年、老年</p>
<p>$$<br>    Gini(D,A_1=1) = \frac{5}{15}[2 \times \frac{2}{5} \times (1-\frac{2}{5})] + \frac{10}{15}[2 \times \frac{7}{10} \times (1-\frac{7}{10})]=0.44\\<br>    Gini(D,A_1=2) = \frac{5}{15}[2\times\frac{3}{5}\times(1-\frac{3}{5})] + \frac{10}{15}[2\times\frac{6}{10}\times(1-\frac{6}{10})]=0.48\\<br>    Gini(D,A_1=3) = \frac{5}{15}[2\times\frac{4}{5}\times(1-\frac{4}{5})] + \frac{10}{15}[2\times\frac{5}{10}\times(1-\frac{5}{10})]=0.44<br>$$<br>其中$Gini(D,A_1=1)$和$Gini(D,A_1=3)$最小，所以$A_1=1$和$A_1=3$均可做为$A_1$的最优切分点</p>
<p>&emsp;&emsp;求特征$A_2$的基尼指数，以1，2表示有工作和没有工作<br>$$<br>    Gini(D,A_2=1) = \frac{5}{15}[2\times\frac{5}{5}\times(1-\frac{5}{5})] + \frac{10}{15}[2\times\frac{4}{10}\times(1-\frac{4}{10})]=0.32<br>$$<br>$A_2$只有一个切分点即$A_2=1$</p>
<p>&emsp;&emsp;求特征$A_3$的基尼指数，以1，2表示有房子和没有房子<br>$$<br>    Gini(D,A_3=1) = \frac{6}{15}[2\times\frac{6}{6}\times(1-\frac{6}{6})] + \frac{9}{15}[2\times\frac{3}{9}\times(1-\frac{3}{9})]=0.27<br>$$<br>$A_3$只有一个切分点即$A_3=1$</p>
<p>&emsp;&emsp;求特征$A_4$的基尼指数，以1，2，3表示信贷情况为非常好、好和一般<br>$$<br>    Gini(D,A_4=1) = \frac{4}{15}[2\times\frac{4}{4}\times(1-\frac{4}{4})] + \frac{11}{15}[2\times\frac{6}{11}\times(1-\frac{6}{11})]=0.36\\<br>    Gini(D,A_4=2) = \frac{6}{15}[2\times\frac{4}{6}\times(1-\frac{4}{6})] + \frac{9}{15}[2\times\frac{5}{9}\times(1-\frac{5}{9})]=0.47\\<br>    Gini(D,A_4=3) = \frac{5}{15}[2\times\frac{1}{5}\times(1-\frac{1}{5})] + \frac{10}{15}[2\times\frac{8}{10}\times(1-\frac{8}{10})]=0.32<br>$$</p>
<p>其中$Gini(D,A_4=3)$最小，所以$A_4=3$为$A_4$的最优切分点</p>
<p>&emsp;&emsp;在4个特征中，$Gini(D,A_3=1)=0.27$最小，所以选择$A_3$为最优特征，$A_3=1$为其最优切分点。其中$A_3=1$的结点包含数据4、8、9、10、11，$A_3 \neq 1$结点包含数据1，2，3，5，6，7，13，14，15。$A_3=1$结点内数据类别相同，所以形成叶子结点。对$A_3 \neq 1$结点继续重复上述过程。</p>
<p>&emsp;&emsp;数据如下</p>
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">年龄</th>
<th style="text-align:center">有工作</th>
<th style="text-align:center">信贷情况</th>
<th style="text-align:center">类别</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">好</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">好</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">12</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">13</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">14</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">非常好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">15</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
<p>&emsp;&emsp;求特征$A_1$的基尼指数<br>$$<br>    Gini(D,A_1=1) = \frac{4}{10}[2\times\frac{1}{4}\times(1-\frac{1}{4})] + \frac{6}{10}[2\times\frac{3}{6}\times(1-\frac{3}{6})]=0.45\\<br>    Gini(D,A_1=2) = \frac{2}{10}[2\times\frac{0}{2}\times(1-\frac{0}{2})] + \frac{8}{10}[2\times\frac{4}{8}\times(1-\frac{4}{8})]=0.4\\<br>    Gini(D,A_1=3) = \frac{4}{10}[2\times\frac{3}{4}\times(1-\frac{3}{4})] + \frac{6}{10}[2\times\frac{1}{6}\times(1-\frac{1}{6})]=0.32<br>$$<br>其中$Gini(D,A_1=3)$最小，所以$A_1=3$是$A_1$的最优切分点</p>
<p>&emsp;&emsp;求特征$A_2$的基尼指数<br>$$<br>    Gini(D,A_2=1) = \frac{3}{10}[2\times\frac{3}{3}\times(1-\frac{3}{3})] + \frac{7}{10}[2\times\frac{1}{7}\times(1-\frac{1}{7})]=0.17<br>$$<br>$A_2$只有一个切分点即$A_2=1$</p>
<p>&emsp;&emsp;求特征$A_4$的基尼指数<br>$$<br>    Gini(D,A_4=1) = \frac{1}{10}[2\times\frac{1}{1}\times(1-\frac{1}{1})] + \frac{9}{10}[2\times\frac{3}{9}\times(1-\frac{3}{9})]=0.4\\<br>    Gini(D,A_4=2) = \frac{5}{10}[2\times\frac{3}{5}\times(1-\frac{3}{5})] + \frac{5}{10}[2\times\frac{1}{5}\times(1-\frac{1}{5})]=0.4\\<br>    Gini(D,A_4=3) = \frac{4}{10}[2\times\frac{0}{0}\times(1-\frac{0}{0})] + \frac{6}{10}[2\times\frac{4}{6}\times(1-\frac{4}{6})]=0.27<br>$$</p>
<p>其中$Gini(D,A_4=3)$最小，所以$A_4=3$为$A_4$的最优切分点</p>
<p>&emsp;&emsp;在4个特征中，$Gini(D,A_2=1)=0.17$最小，所以选择$A_2$为最优特征，$A_2=1$为其最优切分点。其中$A_2=1$的结点包含数据3、13、14，$A_3 \neq 1$结点包含数据1、2、5、6、7、12、15。$A_2=1$结点内数据类别相同，所以形成叶子结点。对$A_2 \neq 1$结点内数据类别相同，所以形成叶子结点。</p>
<p>&emsp;&emsp;到此，CART树生成完毕。可以发现与之前按照ID3算法所生成的决策树一样，如下图。</p>
<div align="center"><br>    <img src="/CART-分类与回归树/决策树.png" alt="决策树模型结构"><br></div>


<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li>机器学习实战，人民邮电出版社</li>
<li>统计学习方法，清华大学出版社</li>
</ol>

          
        
      
    </div>
    
    
    



    

    <div>
      
    </div>

    <div>
      
    </div>

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yajian.github.io/决策树/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小建儿">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小建儿的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/决策树/" itemprop="url">决策树</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-10T21:00:03+08:00">
                2018-12-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/决策树/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="决策树/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;决策树(decision tree)是一种多功能的机器学习算法，它可以实现分类和回归任务，同时也是随机森林的重要组成部分，本篇博客主要讨论用于分类的决策树。</p>
<p>&emsp;&emsp;分类型决策树是一种描述对实例进行分类的树形结构。决策树由结点（node）和有向边（directed edge）组成。结点有两种类型：内部结点（internal node）和叶结点（leaf node）。内结点表示一个特征，叶子结点表示一个类别。</p>
<h1 id="相关数学概念"><a href="#相关数学概念" class="headerlink" title="相关数学概念"></a>相关数学概念</h1><h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h2><p>&emsp;&emsp;在将实例分配到子结点的过程中需要选择一个度量条件来判断该实例属于哪个子结点，常见的方法是用信息熵作为度量条件。</p>
<p>&emsp;&emsp;在信息论中，熵（entropy）表示随机变量不确定性的度量，设$X$是一个取有限个值的离散随机变量，其概率分布为<br>$$P(X=x_i)=p_i, i=1,2,…,n$$<br>则随机变量$X$的熵的定义为<br>$$<br>H(X)=-\sum_{i=1}^{n}p_ilog_{2}p_i<br>\tag{1}<br>$$<br>若$p_i=0$，则定义$0log0=0$。熵越大，说明随机变量的不确定性越大。</p>
<h2 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h2><p>&emsp;&emsp;设有随机变量(X,Y)，其联合概率分布为<br>$$P(X=x_i,Y=y_i)=p_{ij}, i=1,2,…,n;j=1,2,…,m$$<br>条件熵H(Y|X)表示在已知随机变量$X$的条件下随机变量$Y$的不确定性。随机变量$X$给定的条件下随机变量$Y$的条件熵H(Y|X)，定义为$X$给定条件下$Y$的条件概率分布的熵对$X$的数学期望。<br>$$P(Y|X)=\sum_{i=1}^{n}p_iH(Y|X=x_i)$$<br>其中$p_i=P(X=x_i)$</p>
<p>&emsp;&emsp;当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的熵和条件熵分别称为经验熵(empirical entropy)和经验条件熵(empirical conditional entropy).</p>
<h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><p>&emsp;&emsp;信息增益(information gain)表示得知特征$X$的信息而使得类别$Y$的信息不确定性减少的程度。</p>
<p>&emsp;&emsp;特征A对训练数据集D的信息增益$g(D,A)$，定义为集合D的经验熵$H(D)$与特征A给定的条件下D的经验条件熵$H(D|A)$之差，即<br>$$g(D,A)=H(D)-H(D|A)$$</p>
<p>&emsp;&emsp;一般地，熵$H(Y)$与条件熵$H(Y|X)$之差称为互信息，决策树中的信息增益等价于训练数据集中类别和特征的互信息。</p>
<h2 id="信息增益比"><a href="#信息增益比" class="headerlink" title="信息增益比"></a>信息增益比</h2><p>&emsp;&emsp;特征A对训练数据集D的信息增益比$g_R(D,A)$定义为其信息增益$g(D,A)$与训练数据集$D$的经验熵$H(D)$之比<br>$$g_R(D,A)=\frac{g(D,A)}{H(D)}$$</p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>&emsp;&emsp;决策树在建模过程中使用信息增益准则选择特征，给定训练集$D$和特征$A$，经验熵$H(D)$表示对数据集$D$进行分类的不确定性。而经验条件熵$H(D|A)$表示在特征$A$给定的条件下对数据集$D$进行分类的不确定性，它们的差即信息增益，表示由于特征$A$而使得对数据集$D$的分类的不确定性减少的程度。显然，对于数据集$D$而言，信息增益依赖于特征，不同的特征具有不同的信息增益，信息增益大的特征具有更强的分类能力。</p>
<p>&emsp;&emsp;根据信息增益准则的特征选择方法是：对训练数据集$D$，计算其每个特征的信息增益，并比较它们的大小，选择信息增益大的特征。</p>
<h2 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h2><p>&emsp;&emsp;设训练数据集为$D$，$|D|$表示其样本容量，即样本个数。设有$K$个类$C_k，k=1,2,…,K$，$|C_k|$为属于$C_k$的样本个数，$\sum_{k=1}^{K}|C_k|=|D|$。设特征$A$有$n$个不同的取值${a_1,a_2,…,a_n}$，根据特征$A$的取值将$D$划分为n个子集$D_1,D_2,…,D_n$，$|D_i|$为$D_i$的样本个数，$\sum_{k=1}^{n}|D_i|=|D|$。记子集$D_i$中属于类$C_k$的样本的集合为$D_{ik}$，记$D_{ik}=D_i \cap C_k$，$|D_{ik}|$为$D_{ik}$的样本个数。</p>
<p>&emsp;&emsp;ID3算法如下</p>
<ul>
<li>输入： 训练数据集$D$，特征集$A$，阈值$\epsilon$</li>
<li>输出： 决策树$T$</li>
</ul>
<ol>
<li>若$D$中所有实例属于同一类别$C_k$，则$T$为单结点树，并将类$C_k$作为该结点的类标记，返回$T$；</li>
<li>若$A=\emptyset$，则$T$为单点树，将$D$中实例数最多的类$C_k$作为该结点的类标记，返回$T$；</li>
<li><p>否则，如下计算$A$中各特征对$D$的信息增益，选择信息增益最大的特征$A_g$</p>
<ol>
<li>计算数据集$D$的经验熵<br>$$H(D)=-\sum_{k=1}^{K}\frac{|C_k|}{|D|}log_2\frac{|C_k|}{|D|}$$ </li>
<li>计算特征集$A$对数据集$D$的经验条件熵<br>$$H(D|A)=\sum_{i=1}^{n}\frac{|D_i|}{|D|}H(D_i)=\sum_{i=1}^{n}[\frac{|D_i|}{|D|}\sum_{k=1}^{K}\frac{|D_{ik}|}{|D_{i}|}log_2\frac{|D_{ik}|}{|D_{i}|}]$$</li>
<li>计算信息增益<br>$$g(D,A)=H(D) - H(D|A)$$</li>
</ol>
</li>
<li><p>如果$A_g$小于阈值$\epsilon$，则置$T$为单点树，将$D$中实例数最多的类$C_k$作为该结点的类标记，返回$T$；</p>
</li>
<li>否则，对$A_g$的每一个值$a_i$，按照$A_g=a_i$将$D$分割为若干非空子集$D_i$，将$D_i$中实例最大的类作为标记，构建子结点，由结点和子结点构成树$T$，返回$T$</li>
<li>对第$i$个子结点，以$D_i$为训练集，以$A_i-{A_g}$为特征集，递归地调用步骤1-5，得到子树$T_i$，返回$T_i$</li>
</ol>
<h2 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h2><p>&emsp;&emsp;C4.5算法和ID3算法类似，C4.5算法对ID3算法进行了改进，在生成模型的过程中采用信息增益比来选择特征。</p>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><p>&emsp;&emsp;以贷款申请数据为例讲解决策树的生成过程，采用ID3算法。</p>
<table>
<thead>
<tr>
<th style="text-align:center">ID</th>
<th style="text-align:center">年龄</th>
<th style="text-align:center">有工作</th>
<th style="text-align:center">有自己的房子</th>
<th style="text-align:center">信贷情况</th>
<th style="text-align:center">类别</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">好</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
<td style="text-align:center">好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">青年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">好</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">9</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">非常好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">10</td>
<td style="text-align:center">中年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">非常好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">11</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">非常好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">12</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">13</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
<td style="text-align:center">好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">14</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
<td style="text-align:center">非常好</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">15</td>
<td style="text-align:center">老年</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
<ol>
<li>计算经验熵$H(D)$<br> $$H(D)=-\frac{6}{15}log_2\frac{6}{15}-\frac{9}{15}log_2\frac{9}{15}=0.971$$</li>
<li><p>计算各特征对数据集$D$的信息增益</p>
<ul>
<li>年龄<br>$$<br>\begin{split}<br>g(D,A_1)&amp;=H(D) - [\frac{5}{15}H(D_1)+\frac{5}{15}H(D_2)+\frac{5}{15}H(D_3)]\\<br>&amp;= 0.971 - {\frac{5}{15}[-\frac{2}{5}log_2\frac{2}{5}-\frac{3}{5}log_2\frac{3}{5}]+<br>\frac{5}{15}[-\frac{3}{5}log_2\frac{3}{5}-\frac{2}{5}log_2\frac{2}{5}]+<br>\frac{5}{15}[-\frac{4}{5}log_2\frac{4}{5}-\frac{1}{5}log_2\frac{1}{5}]}\\<br>&amp;=0.971-0.888\\<br>&amp;=0.083<br>\end{split}<br>$$</li>
<li>有工作<br>$$<br>\begin{split}<br>g(D,A_2)&amp;=H(D) - [\frac{5}{15}H(D_1)+\frac{10}{15}H(D_2)]\\<br>&amp;= 0.971 - {\frac{5}{15} \times 0+<br>\frac{10}{15}[-\frac{6}{10}log_2\frac{6}{10}-\frac{4}{10}log_2\frac{4}{10}]}\\<br>&amp;=0.971-0.647\\<br>&amp;=0.324<br>\end{split}<br>$$</li>
<li>有自己的房子<br>$$<br>\begin{split}<br>g(D,A_3)&amp;=H(D) - [\frac{6}{15}H(D_1)+\frac{9}{15}H(D_2)]\\<br>&amp;= 0.971 - {\frac{6}{15} \times 0+<br>\frac{9}{15}[-\frac{3}{9}log_2\frac{3}{9}-\frac{6}{9}log_2\frac{6}{9}]}\\<br>&amp;=0.971-0.551\\<br>&amp;=0.420<br>\end{split}<br>$$</li>
<li>信贷情况<br>$$<br>\begin{split}<br>g(D,A_3)&amp;=H(D) - [\frac{5}{15}H(D_1)+\frac{6}{15}H(D_2)+\frac{4}{15}H(D_2)]\\<br>&amp;= 0.971 - {\frac{5}{15}[-\frac{1}{5}log_2\frac{1}{5}-\frac{4}{5}log_2\frac{4}{5}] +<br>\frac{6}{15}[-\frac{4}{6}log_2\frac{4}{6}-\frac{2}{6}log_2\frac{2}{6}] +<br>\frac{4}{15} \times 0  }\\<br>&amp;=0.971-0.608\\<br>&amp;=0.363<br>\end{split}<br>$$<br>&emsp;&emsp;综上，特征$A_3$（有自己的房子）的信息增益值最大，所以选择$A_3$作为根节点的特征。接下来将数据集$D$划分为两个子集$D_1$($A_3$=是)、$D_2$($A_3$=否)，分别进行下一轮的信息增益筛选。</li>
</ul>
</li>
</ol>
<ol start="3">
<li>进入子集$D_1$($A_3$=是)，由于该子集中只有一个类别，所以形成叶子结点，结点的标记就是类别。</li>
<li><p>进入子集$D_2$($A_3$=否)，数据如下</p>
<ul>
<li><p>计算经验熵<br>$$H(D_2)=-\frac{6}{9}log_2\frac{6}{9}-\frac{3}{9}log_2\frac{3}{9}=0.918$$</p>
</li>
<li><p>年龄特征信息增益<br>$$<br>\begin{split}<br>g(D_2,A_1)&amp;=H(D) - [\frac{4}{9}H(D_1)+\frac{2}{9}H(D_2)+\frac{3}{9}H(D_3)]\\<br>&amp;= 0.971 - {\frac{4}{9}[-\frac{3}{4}log_2\frac{3}{4}-\frac{1}{4}log_2\frac{1}{4}]+<br>\frac{2}{9}\times0+<br>\frac{3}{9}[-\frac{2}{3}log_2\frac{2}{3}-\frac{1}{3}log_2\frac{1}{3}]}\\<br>&amp;=0.971-0.667\\<br>&amp;=0.251<br>\end{split}<br>$$</p>
</li>
<li><p>有工作特征信息增益</p>
</li>
</ul>
<p>$$<br> \begin{split}<br> g(D_2,A_2)&amp;=H(D) - [\frac{6}{9}H(D_1)+\frac{3}{9}H(D_2)]\\<br> &amp;= 0.971 - [\frac{6}{9}\times0+\frac{3}{9} \times 0]\\<br> &amp;= 0.918-0\\<br> &amp;=0.918<br> \end{split}<br> $$</p>
<ul>
<li><p>信贷情况特征信息增益</p>
<p>  $$<br>\begin{split}<br>g(D_2,A_4)&amp;=H(D) - [\frac{4}{9}H(D_1)+\frac{4}{9}H(D_2)+\frac{1}{9}H(D_3)]\\<br>&amp;= 0.971 - {\frac{4}{9}\times0+<br>\frac{4}{9}[-\frac{2}{4}log_2\frac{2}{4}-\frac{2}{4}log_2\frac{2}{4}]+<br>\frac{1}{9}\times0}\\<br>&amp;=0.918-0.444\\<br>&amp;=0.474<br>\end{split}<br>$$<br>&emsp;&emsp;综上，特征$A_2$（有工作）的信息增益值最大，所以选择$A_2$作为该结点的特征。接下来将数据集$D_2$划分为两个子集$D_{21}$($A_2$=是)、$D_{22}$($A_2$=否)，分别进行下一轮的信息增益筛选。</p>
</li>
</ul>
</li>
<li><p>进入子集$D_{21}$($A_2$=是)，由于该子集中只有一个类别，所以形成叶子结点，结点的标记就是类别</p>
</li>
<li>进入子集$D_{22}$($A_2$=否)，由于该子集中只有一个类别，所以形成叶子结点，结点的标记就是类别</li>
</ol>
<p>&emsp;&emsp;最终产生的决策树模型如下图所示</p>
<div align="center"><br>    <img src="/决策树/决策树.png" alt="决策树模型结构"><br></div>

<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"><span class="keyword">import</span> pygraphviz <span class="keyword">as</span> pgv</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="comment"># 数据集总条数</span></span><br><span class="line">    numEntries = len(dataSet)</span><br><span class="line">    labelCount = &#123;&#125;</span><br><span class="line">    <span class="comment"># 计算每个类别样本的数量</span></span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        currentLabel = featVec[<span class="number">-1</span>]</span><br><span class="line">        labelCount[currentLabel] = labelCount.get(currentLabel, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">    shannonEnt = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCount:</span><br><span class="line">        <span class="comment"># 计算每个类别出现的概率</span></span><br><span class="line">        prob = float(labelCount[key]) / numEntries</span><br><span class="line">        <span class="comment"># 计算信息熵</span></span><br><span class="line">        shannonEnt -= prob * log(prob, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> shannonEnt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span><span class="params">(dataSet, axis, value)</span>:</span></span><br><span class="line">    retDataSet = []</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="comment"># 挑选第axis个特征的值为value的数据</span></span><br><span class="line">        <span class="keyword">if</span> featVec[axis] == value:</span><br><span class="line">            reducedFeature = featVec[:axis]</span><br><span class="line">            reducedFeature.append(featVec[axis + <span class="number">1</span>:])</span><br><span class="line">            <span class="comment"># 注意，此处是extend，不是append</span></span><br><span class="line">            retDataSet.extend(reducedFeature)</span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    <span class="comment"># 特征数量，由于最后一个是标签，所以减1</span></span><br><span class="line">    numFeatures = len(dataSet[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line">    <span class="comment"># 计算经验熵</span></span><br><span class="line">    baseEntropy = calcShannonEnt(dataSet)</span><br><span class="line">    bestInfoGain = <span class="number">0.0</span></span><br><span class="line">    bestFeature = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):</span><br><span class="line">        <span class="comment"># 把第i个特征全部挑出</span></span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">        <span class="comment"># 第i个特征有几个不同的特征值</span></span><br><span class="line">        uniqueVals = set(featList)</span><br><span class="line">        <span class="comment"># 条件经验熵</span></span><br><span class="line">        newEntropy = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">            <span class="comment"># 把特征值等于value的数据挑出</span></span><br><span class="line">            subDataSet = splitDataSet(dataSet, i, value)</span><br><span class="line">            <span class="comment"># 计算特征值等于value的数据占总样本的比例</span></span><br><span class="line">            prob = len(subDataSet) / float(len(dataSet))</span><br><span class="line">            <span class="comment"># 计算经验条件熵</span></span><br><span class="line">            newEntropy += prob * calcShannonEnt(subDataSet)</span><br><span class="line">        <span class="comment"># 计算信息增益</span></span><br><span class="line">        infoGain = baseEntropy - newEntropy</span><br><span class="line">        <span class="keyword">if</span> infoGain &gt; bestInfoGain:</span><br><span class="line">            bestInfoGain = infoGain</span><br><span class="line">            bestFeature = i</span><br><span class="line">    <span class="keyword">return</span> bestFeature</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(classList)</span>:</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        classCount[vote] = classCount.get(vote, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">    sortedClassCount = sorted(classCount.iteritems(), key=<span class="keyword">lambda</span> item: item[<span class="number">1</span>], reverse=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, labels)</span>:</span></span><br><span class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList):</span><br><span class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)</span><br><span class="line">    bestFeat = chooseBestFeatureToSplit(dataSet)</span><br><span class="line">    bestFeatLabel = labels[bestFeat]</span><br><span class="line">    myTree = &#123;bestFeatLabel: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">del</span> (labels[bestFeat])</span><br><span class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    uniqueVals = set(featValues)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">        subLabels = labels[:]</span><br><span class="line">        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)</span><br><span class="line">    <span class="keyword">return</span> myTree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    dataSet = [[<span class="string">'1'</span>, <span class="string">'1'</span>, <span class="string">'yes'</span>],</span><br><span class="line">               [<span class="string">'1'</span>, <span class="string">'1'</span>, <span class="string">'yes'</span>],</span><br><span class="line">               [<span class="string">'1'</span>, <span class="string">'0'</span>, <span class="string">'no'</span>],</span><br><span class="line">               [<span class="string">'0'</span>, <span class="string">'1'</span>, <span class="string">'no'</span>],</span><br><span class="line">               [<span class="string">'0'</span>, <span class="string">'1'</span>, <span class="string">'no'</span>]]</span><br><span class="line">    labels = [<span class="string">'no surfacing'</span>, <span class="string">'flippers'</span>]</span><br><span class="line">    <span class="keyword">return</span> dataSet, labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    dataSet, labels = createDataSet()</span><br><span class="line">    tree = createTree(dataSet, labels)</span><br><span class="line">    <span class="keyword">print</span> tree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li>机器学习实战，人民邮电出版社</li>
<li>统计学习方法，清华大学出版社</li>
</ol>

          
        
      
    </div>
    
    
    



    

    <div>
      
    </div>

    <div>
      
    </div>

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yajian.github.io/逻辑回归/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小建儿">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小建儿的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/逻辑回归/" itemprop="url">逻辑回归</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-06T14:15:09+08:00">
                2018-12-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/逻辑回归/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="逻辑回归/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;机器学习主要解决两类问题：回归和分类，上篇文章中的线性回归模型是回归模型的一种，但并不能用于分类问题，本文将介绍一种可以用于分类问题的回归算法–logistic回归。</p>
<p>&emsp;&emsp;利用logistic回归进行分类的主要思想是：估算某个实例属于特定类别的概率，如果预估概率超过50%，则属于该类别；反之，属于其他类别，这样形成了一个简单的二元分类器。</p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><h2 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h2><p>&emsp;&emsp;我们希望能找到一种根据输入值输出0，1分类的函数，脑海中闪现的第一个函数应该就是单位阶跃函数，即<br>$$<br>\delta(x)=<br>    \begin{cases}<br>        0, &amp; x \leq 0; \\<br>        1, &amp; x&gt;0.<br>    \end{cases}<br>$$<br>但是该函数在$x=0$处不可导，对于公式推导来说有很大问题，所以大牛们找到了sigmoid函数来代替阶跃函数。</p>
<p>&emsp;&emsp;Sigmoid函数公式如下</p>
<p>$$<br>    f(x)=\frac{1}{1+e^{-x}}<br>    \tag{1}<br>$$</p>
<p>其函数图像如下所示</p>
<div align="center"><br>    <img src="/逻辑回归/sigmoid.png" width="450" height="300" title="sigmoid函数图像"><br></div>

<h2 id="logistic回归模型"><a href="#logistic回归模型" class="headerlink" title="logistic回归模型"></a>logistic回归模型</h2><p>&emsp;&emsp;将公式1推广到多维场景：给每个特征都乘以一个回归系数并相加，即$z=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+……+\theta_{n}x_{n}=\theta ^{T}x$（线性回归），然后将总和带入sigmoid函数中得到<br>$$<br>h_{\theta}\left(x \right)=\frac{1}{1+e^{-z}}=\frac{1}{1+e^{-\theta ^{T}x}}<br>\tag{2}<br>$$<br>&emsp;&emsp;所以线性回归的的结果被映射到了sigmoid函数中。在sigmoid函数图像中可以看出，其函数值介于0～1，中间值为0.5，因此$h_{\theta}\left(x \right)$的输出可以看作分类的概率。当$h_{\theta}\left(x \right)&gt;0.5$，说明$x$属于A类；反之，$h_{\theta}\left(x \right)&lt;0.5$，则$x$属于B类。</p>
<h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><p>&emsp;&emsp;对于给定的数据集$T={(x_1,y_1),(x_2,y_2),…(x_n,y_n)}$，其中$x_i \in R^n$，$y_i \in {0,1}$。分类结果为1的概率表示为<br>$$<br>        P(y=1|x;\theta)=h_\theta(x)<br>$$<br>分类结果为0的概率表示为<br>$$<br>        P(y=0|x;\theta)=1-h_\theta(x)<br>$$<br>将其合并则有<br>$$<br>p(y|x;\theta)=h_\theta(x_i) ^{y_i}(1-h_\theta(x))^{1-y_i}<br>$$<br>因为m个样本互相独立，所以其联合分布可以看作各个样本概率之积，则似然函数为<br>$$<br>    L(\theta) = \prod_{i=1}^{n}p(y_i|x_i;\theta)=\prod_{i=1}^{n} [h_\theta(x_i)]^{y_i}[1-h_\theta(x_i)]^{1-y_i}<br>$$<br>取对数似然<br>$$<br>l(\theta) =\sum_{i=1}^{n} y_ilog[h_\theta(x_i)]+(1-y_i)log[1-h_\theta(x)]<br>\tag{3}<br>$$<br>当$l\left(\theta \right)$取最大值时，$\theta$的值为最终的解。求$l\left(\theta \right)$对$\theta$的导数 </p>
<p>$$<br>\begin{split}<br>    l^{‘}(\theta)&amp;=\sum_{i=1}^{n} [\frac{y_i}{h_\theta(x_i)}-\frac{1-y_i}{1-h_\theta(x_i)}] \cdot h^{‘}_\theta(x_i)\\<br>    &amp;=\sum_{i=1}^{n} [\frac{y_i}{h_\theta(x_i)}-\frac{1-y_i}{1-h_\theta(x_i)}]\cdot[h_\theta(x_i)]^{‘}_{z} \cdot z^{‘}_\theta\\<br>    &amp;=\sum_{i=1}^{n}[\frac{y_i}{h_\theta(x_i)}-\frac{1-y_i}{1-h_\theta(x_i)}] \cdot h_\theta(x_i)[1-h_\theta(x_i)] \cdot z^{‘}_\theta \\<br>    &amp;=\sum_{i=1}^{n}[y_i-h_\theta(x_i)] \cdot x_i<br>    \end{split}<br>\tag{4}<br>$$</p>
<p><font face="宋体" size="2">* 注：sigmoid求导结果<br>$$<br>f’\left(x \right)=f\left(x \right)\left[1-f\left(x \right) \right]<br>$$ </font></p>
<p>&lt;\font&gt;<br>对公式4进行迭代，可求得参数$\theta$。</p>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><h3 id="对偏置项b的处理"><a href="#对偏置项b的处理" class="headerlink" title="对偏置项b的处理"></a>对偏置项b的处理</h3><p>&emsp;&emsp;在大部分资料中，会在输入$x$和权重$\theta$中增加一列常数列作为偏置项，这样做的好处是不需要对其进行单独处理，可随权重$\theta$一起求解，下面来讨论一下单独求解偏置项$b$的步骤。</p>
<p>&emsp;&emsp;假设输入为$[x_1,x_2,…,x_n]$，权重为$[\theta_1,\theta_2,…,\theta_n]$，偏置项为$[b_1,b_2,…,b_n]$，则公式2变为<br>$$<br>    h_{\theta}\left(x \right)=\frac{1}{1+e^{-z}}=\frac{1}{1+e^{-\theta ^{T}x-b}}<br>$$<br>接下来需让公示3对变量b求导<br>$$<br>\begin{split}<br>    l^{‘}(b)&amp;=\sum_{i=1}^{n} [\frac{y_i}{h_\theta(x_i)}-\frac{1-y_i}{1-h_\theta(x_i)}] \cdot h^{‘}_\theta(x_i)\\<br>    &amp;=\sum_{i=1}^{n} [\frac{y_i}{h_\theta(x_i)}-\frac{1-y_i}{1-h_\theta(x_i)}] \cdot [h_\theta(x_i)]^{‘}_{z} \cdot z^{‘}_b\\<br>    &amp;=\sum_{i=1}^{n}[\frac{y_i}{h_\theta(x_i)}-\frac{1-y_i}{1-h_\theta(x_i)}] \cdot h_\theta(x_i)[1-h_\theta(x_i)] \cdot z^{‘}_b \\<br>    &amp;=\sum_{i=1}^{n}[y_i-h_\theta(x_i)] \cdot x_i<br>    \end{split}<br>\tag{5}<br>$$<br>对公式5进行迭代，可求得参数$b$。</p>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>&emsp;&emsp;为了加深对公示的理解，代码没有直接使用tensorflow内置的优化器，手动实现了逻辑回归梯度下降。示例如下：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="built_in">import</span> tensorflow as tf</span><br><span class="line">from sklearn <span class="built_in">import</span> datasets</span><br><span class="line"><span class="built_in">import</span> numpy as np</span><br><span class="line">from sklearn.preprocessing <span class="built_in">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line"><span class="attr">iris</span> = datasets.load_iris()</span><br><span class="line"><span class="attr">data_x</span> = np.array(iris['data'])</span><br><span class="line"><span class="attr">data_y</span> = np.array(iris['target']).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">print data_x.shape</span><br><span class="line">print data_y.shape</span><br><span class="line"><span class="attr">enc</span> = OneHotEncoder()</span><br><span class="line">enc.fit(data_y)</span><br><span class="line"><span class="comment"># 多分类问题，对label进行one-hot编码</span></span><br><span class="line"><span class="attr">targets</span> = enc.transform(data_y).toarray()</span><br><span class="line"><span class="comment"># 输入行数不指定，列数为特征个数</span></span><br><span class="line"><span class="attr">X</span> = tf.placeholder(<span class="attr">dtype=tf.float32,</span> <span class="attr">shape=(None,</span> data_x.shape[<span class="number">1</span>]))</span><br><span class="line"><span class="comment"># 输出行数不指定，列数类别个数</span></span><br><span class="line"><span class="attr">y</span> = tf.placeholder(<span class="attr">dtype=tf.float32,</span> <span class="attr">shape=(None,</span> <span class="number">3</span>))</span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line"><span class="attr">alpha</span> = <span class="number">0.0001</span></span><br><span class="line"><span class="comment"># 迭代次数</span></span><br><span class="line"><span class="attr">epoch</span> = <span class="number">500</span></span><br><span class="line"><span class="comment"># 权重</span></span><br><span class="line"><span class="attr">theta</span> = tf.Variable(tf.random_uniform([data_x.shape[<span class="number">1</span>], <span class="number">3</span>], -<span class="number">1.0</span>, <span class="number">1.0</span>), <span class="attr">name='theta')</span></span><br><span class="line"><span class="comment"># 偏置</span></span><br><span class="line"><span class="attr">b</span> = tf.Variable(tf.random_uniform([<span class="number">3</span>], -<span class="number">1.0</span>, <span class="number">1.0</span>), <span class="attr">name='b')</span></span><br><span class="line"><span class="comment"># 预测值</span></span><br><span class="line"><span class="attr">predict_y</span> = tf.nn.softmax(tf.matmul(X, theta) + b)</span><br><span class="line"><span class="comment"># 误差</span></span><br><span class="line"><span class="attr">error</span> = tf.cast(y, tf.float32) - predict_y</span><br><span class="line"><span class="comment"># 代价函数，使用交叉熵函数，手动实现</span></span><br><span class="line"><span class="attr">cost</span> = tf.reduce_mean(-tf.reduce_sum(y * tf.log(predict_y), <span class="attr">reduction_indices=1))</span></span><br><span class="line"><span class="comment"># 权重的负梯度</span></span><br><span class="line"><span class="attr">theta_gradient</span> = -tf.matmul(tf.matrix_transpose(X), error, <span class="attr">name='theta_gradient')</span></span><br><span class="line"><span class="comment"># 偏置的负梯度</span></span><br><span class="line"><span class="attr">b_gradient</span> = - tf.reduce_mean(tf.matmul(tf.transpose(X), error), <span class="attr">reduction_indices=0,</span> <span class="attr">name='b_gradient')</span></span><br><span class="line"><span class="comment"># 权重迭代项</span></span><br><span class="line"><span class="attr">training_op1</span> = tf.assign(theta, theta - alpha * theta_gradient)</span><br><span class="line"><span class="comment"># 偏置迭代项</span></span><br><span class="line"><span class="attr">training_op2</span> = tf.assign(b, b - alpha * b_gradient)</span><br><span class="line"><span class="comment"># 全局初始化</span></span><br><span class="line"><span class="attr">init</span> = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() as sess:</span><br><span class="line">    init.run()</span><br><span class="line">    for i <span class="keyword">in</span> range(epoch):</span><br><span class="line">        sess.run([training_op1, training_op2, cost], <span class="attr">feed_dict=&#123;X:</span> data_x, y: targets&#125;)</span><br><span class="line">        print sess.run(theta, <span class="attr">feed_dict=&#123;X:</span> data_x, y: targets&#125;)</span><br><span class="line">        print sess.run(b, <span class="attr">feed_dict=&#123;X:</span> data_x, y: targets&#125;)</span><br><span class="line">        print sess.run(cost, <span class="attr">feed_dict=&#123;X:</span> data_x, y: targets&#125;)</span><br></pre></td></tr></table></figure>
<p>代码详见<a href="https://github.com/yajian/machine_learning/blob/master/logistic_regression/lr_model.py" target="_blank" rel="noopener">逻辑回归代码</a></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://blog.csdn.net/wc781708249/article/details/79290523" target="_blank" rel="noopener">Tensorflow实现梯度下降各种方法</a></li>
<li>机器学习实战-基于Scikit-Learn和Tensorflow，机械工业出版社</li>
<li>机器学习实战，人民邮电出版社</li>
</ol>

          
        
      
    </div>
    
    
    



    

    <div>
      
    </div>

    <div>
      
    </div>

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yajian.github.io/线性回归/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小建儿">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小建儿的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/线性回归/" itemprop="url">线性回归</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-27T21:07:43+08:00">
                2018-11-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/线性回归/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="线性回归/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>&emsp;&emsp;说到回归一般都指线性回归，回归的目的是预测数值型的目标值。线性回归模型的优点在于结果易于理解，计算简单，缺点在于对非线性的数据拟合不好。</p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>&emsp;&emsp;线性回归就是对输入特征加权求和，在加上偏置项进行预测。公式如下所示：</p>
<p>$$<br>                    \widehat{h}=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+…+\theta_{n}x_{n}<br>                    \tag{1}<br>$$</p>
<p>其中，$\widehat{h}$代表预测值，$n$是特征的个数，${x_i}$代表第i个特征值，$\theta_{i}$ 代表第i个特征的权重，将上式向量化有</p>
<p>$$<br>                            \widehat{h}=h_{\theta}(X)=X\theta<br>                            \tag{2}<br>$$</p>
<p>其中$\theta$是模型的参数向量，X是实例的特征向量，$h_{\theta}$是使用模型参数$\theta$做参数的假设函数。</p>
<font face="宋体" size="2">* 注：这里为什么写成$X\theta$的形式，而不是$\theta X$呢？在实际使用中，实例的特征是行向量，由多个实例构成输入矩阵，而权重是列向量，其具体形式如下<br>    $$<br>    X\theta=<br>     \begin{bmatrix}<br>      x_0^1 &amp; x_0^2 &amp; … &amp;x_0^n \\<br>      x_1^1 &amp; x_1^2 &amp; … &amp;x_1^n \\<br>      …  &amp; … &amp; … &amp;… \\<br>      x_m^1 &amp; x_m^1 &amp; … &amp;x_m^1<br>      \end{bmatrix}<br>      \begin{bmatrix}<br>      \theta_0  \\<br>      \theta_1  \\<br>      …   \\<br>      \theta_n<br>      \end{bmatrix}<br>    $$<br></font>

<p>&emsp;&emsp;为了衡量模型效果，一般使用MSE(均方误差，Mean Square Error)描述线性回归的预测值和真实值之间的偏差。假设输入的样本特征为$x_1,x_2,…,x_n$，对应的样本值为$y_1,y_2,y_3,…,y_n$，则MSE的定义为</p>
<p>$$<br>J(\theta)=\frac{1}{2}(\widehat{y}_i-y_i)^2=\frac{1}{2}\sum^n_{i=1}(h_{\theta}(x_i)-y_i)^2<br>\tag{3}<br>$$<br>写成向量形式有<br>$$<br>J(\theta)=\frac{1}{2}(X\theta-Y)^2<br>\tag{4}<br>$$<br>&emsp;&emsp;以上就是线性回归的基本公式和损失函数。</p>
<h1 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h1><p>&emsp;&emsp;我们的目标是找到合适的一组权重$\theta$让$J(\theta)$最小，这样就说明我们的模型越符合实际效果越好。一般有两种方式进行求解，直接求解和梯度下降。</p>
<h2 id="解析求解"><a href="#解析求解" class="headerlink" title="解析求解"></a>解析求解</h2><p>&emsp;&emsp;我们已经拿到了损失函数的表达形式，可以从公式$(4)$中直接推到出$\theta$，过程如下。</p>
<p>$$<br>\begin{split}<br>    J(\theta)=\frac{1}{2}(X\theta-Y)^2&amp;=\frac{1}{2}(X\theta-Y)^T(X\theta-Y)\\<br>    &amp;=\frac{1}{2}(\theta^TX^T-Y^T)(X\theta-Y)\\<br>    &amp;=\frac{1}{2}(\theta^TX^TX\theta-\theta^TX^TY-Y^TX\theta-Y^TY)<br>\end{split}<br>\tag{5}<br>$$<br>&emsp;&emsp;接下来对$J(\theta)$求偏导</p>
<p>$$<br>\begin{split}<br>    \frac{\partial^{2}J(\theta)}{\partial\theta^{2}}&amp;=\frac{1}{2}(2 \cdot X^TX\theta-2 \cdot X^TY)\\<br>    &amp;=X^TX\theta-X^TY<br>\end{split}<br>\tag{6}<br>$$</p>
<font face="宋体" size="2">* 注：这里用到了几个矩阵求导公式<br>$$\frac{dAB}{dB}=A^T$$<br>$$\frac{dA^TB}{dA}=B$$<br>$$\frac{dX^TAX}{dX}=(A+A^T)X$$<br></font>

<p>&emsp;&emsp;令导数为0，有</p>
<p>$$\frac{\partial^{2}J(\theta)}{\partial\theta^{2}}=0$$</p>
<p>$$X^TX\theta-X^TY=0$$</p>
<p>$$X^TX\theta=X^TY$$</p>
<p>$$\theta=(X^TX)^{-1}X^TY \tag{7}$$</p>
<p>&emsp;&emsp;最终推到出$(7)$，直接求解需要用到实例数据$X$及对应的预测值$Y$，在输入不大的情况下可以快速求得权重矩阵。但$(7)$中含有矩阵求逆运算，其算法复杂度通常在$O(n^2.4)$到$O(n^3)$之间，在高维大数据量的情况下直接求解的计算量很大；而且对于某些损失函数是凸函数的模型($X^TX$不可逆)来说，无法求得损失函数的偏导，该方法失效，只能使用梯度下降算法。</p>
<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>&emsp;&emsp;梯度下降是一种通用的优化算法，梯度下降的中心思想就是迭代地调整参数从而使成本函数最小化。</p>
<font face="宋体" size="2">* 注：梯度下降的形象解释：<br>假设你迷失在山上的迷雾中，你能感受到的只有脚下地面的坡度。快速到达山脚的一个策略就是沿着最陡的方向下坡。这就是梯度下降的做法：通过测量参数向量$\theta$相关的误差函数的局部梯度，并不断沿着梯度的方向调整，直到梯度降为0，到达最小值。<br></font>

<p>&emsp;&emsp;具体来说，首先使用一个随机的$\theta$值，即随机初始化，然后逐步改进，每次踏出一步，每一步都尝试降低成本函数，直到算法收敛到一个最小值。梯度下降中一个重要的参数是每一步的步长，该参数被称为学习率。如果学习率太低，算法需要经过大量迭代才能收敛，如果太高，有可能越过最小值甚至比上一步迭代的结果还大，导致模型无法收敛。</p>
<p>&emsp;&emsp;对于线性回归，梯度下降的数学表达形式如下。假设第$i$次迭代的权重为$\theta_i$，学习率为$\eta$，第$i+1$次迭代的权重为<br>$$<br>    \theta_{i+1}=\theta_i-\eta \cdot \frac{\partial^2J(\theta)}{\partial\theta^2}<br>    \tag{8}<br>$$</p>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>&emsp;&emsp;下面使用tensorflow实现两种求解方式，以加州房价预测数据为例。</p>
<h2 id="tensorflow实现解析求解"><a href="#tensorflow实现解析求解" class="headerlink" title="tensorflow实现解析求解"></a>tensorflow实现解析求解</h2><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from sklearn.datasets import fetch_california_housing</span><br><span class="line"></span><br><span class="line">n_epochs = 10000  <span class="comment"># 把样本集数据学习1000次</span></span><br><span class="line">learning_rate = 0.01  <span class="comment"># 步长 学习率 不能太大 太大容易来回震荡 太小 耗时间，跳不出局部最优解</span></span><br><span class="line"><span class="comment"># 可以写learn_rate动态变化，随着迭代次数越来越大 ，学习率越来越小 learning_rate/n_epoches</span></span><br><span class="line">housing = fetch_california_housing()</span><br><span class="line">m, n = housing.data.shape</span><br><span class="line">housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]</span><br><span class="line">housing_data_target = housing.target.reshape(-1, 1)</span><br><span class="line">X = tf.constant(housing_data_plus_bias, tf.float32)</span><br><span class="line">y = tf.constant(housing_data_target, tf.float32)</span><br><span class="line">XT = tf.transpose(X)</span><br><span class="line">theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    theta_value = theta.eval()</span><br><span class="line">    print theta_value</span><br></pre></td></tr></table></figure>
<h2 id="tensorflow实现梯度下降"><a href="#tensorflow实现梯度下降" class="headerlink" title="tensorflow实现梯度下降"></a>tensorflow实现梯度下降</h2><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.datasets import fetch_california_housing</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">n_epochs = 10000  <span class="comment"># 把样本集数据学习1000次</span></span><br><span class="line">learning_rate = 0.01  <span class="comment"># 步长 学习率 不能太大 太大容易来回震荡 太小 耗时间，跳不出局部最优解</span></span><br><span class="line"><span class="comment"># 可以写learn_rate动态变化，随着迭代次数越来越大 ，学习率越来越小 learning_rate/n_epoches</span></span><br><span class="line">housing = fetch_california_housing()</span><br><span class="line">m, n = housing.data.shape</span><br><span class="line">housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]</span><br><span class="line"><span class="comment"># 可以使用TensorFlow或者Numpy或者sklearn的StandardScaler去进行归一化</span></span><br><span class="line"><span class="comment"># 归一化可以最快的找到最优解</span></span><br><span class="line"><span class="comment"># 常用的归一化方式：</span></span><br><span class="line"><span class="comment"># 最大最小值归一化 (x-min)/(max-min)</span></span><br><span class="line"><span class="comment"># 方差归一化 x/方差</span></span><br><span class="line"><span class="comment"># 均值归一化 x-均值 结果有正有负 可以使调整时的速度越来越快。</span></span><br><span class="line">scaler = StandardScaler().fit(housing_data_plus_bias)  <span class="comment"># 创建一个归一化对象</span></span><br><span class="line">scaled_housing_data_plus_bias = scaler.transform(housing_data_plus_bias)  <span class="comment"># 真正执行 因为来源于sklearn所以会直接执行，不会延迟。</span></span><br><span class="line">housing_data_target = housing.target.reshape(-1, 1)</span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, name='X')</span><br><span class="line">y = tf.placeholder(tf.float32, name='y')</span><br><span class="line"></span><br><span class="line"><span class="comment"># random_uniform函数创建图里一个节点包含随机数值，给定它的形状和取值范围，就像numpy里面rand()函数</span></span><br><span class="line">theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')  <span class="comment">#参数\theta，列向量，按照-1.0到1.0随机给</span></span><br><span class="line">y_pred = tf.matmul(X, theta, name=<span class="string">"predictions"</span>)  <span class="comment"># 相乘 m行一列</span></span><br><span class="line">error = y_pred - y  <span class="comment"># 列向量和列向量相减 是一组数</span></span><br><span class="line">mse = tf.reduce_mean(tf.square(error), name=<span class="string">"mse"</span>)  <span class="comment"># 误差平方加和，公式（3）的手动实现</span></span><br><span class="line">gradients = 2.0 / m * tf.matmul(tf.transpose(X), error)  <span class="comment"># 梯度公式</span></span><br><span class="line">training_op = tf.assign(theta, theta - learning_rate * gradients)  <span class="comment"># 即公式(8)，需对该式进行迭代</span></span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(init)  <span class="comment"># 初始化</span></span><br><span class="line"></span><br><span class="line">    for epoch in range(n_epochs):  <span class="comment"># 迭代1000次</span></span><br><span class="line">        if epoch % 100 == 0:</span><br><span class="line">            print(<span class="string">"Epoch"</span>, epoch, <span class="string">"MSE = "</span>,</span><br><span class="line">                  sess.run(mse, feed_dict=&#123;X: scaled_housing_data_plus_bias, y: housing_data_target&#125;))  <span class="comment"># 每运行100次的时候输出</span></span><br><span class="line">        sess.run(training_op, feed_dict=&#123;X: scaled_housing_data_plus_bias, y: housing_data_target&#125;)</span><br><span class="line"></span><br><span class="line">    best_theta = theta.eval()  <span class="comment"># 最后的w参数值</span></span><br><span class="line">    print(best_theta)</span><br></pre></td></tr></table></figure>
<p>以上代码详见<a href="https://github.com/yajian/machine_learning/tree/master/linear_regression" target="_blank" rel="noopener">线性回归tensorflow实现</a></p>
<p>#参考</p>
<ol>
<li><a href="https://www.cnblogs.com/LHWorldBlog/p/8658044.html" target="_blank" rel="noopener">【TensorFlow篇】–Tensorflow框架初始，实现机器学习中多元线性回归</a></li>
<li>机器学习实战-基于Scikit-Learn和Tensorflow，机械工业出版社</li>
<li>机器学习实战，人民邮电出版社</li>
</ol>

          
        
      
    </div>
    
    
    



    

    <div>
      
    </div>

    <div>
      
    </div>

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yajian.github.io/storm系列3-Topology创建过程/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小建儿">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小建儿的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/storm系列3-Topology创建过程/" itemprop="url">storm系列3:Topology创建过程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-22T16:16:48+08:00">
                2018-08-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/storm/" itemprop="url" rel="index">
                    <span itemprop="name">storm</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/storm系列3-Topology创建过程/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="storm系列3-Topology创建过程/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Topology创建过程"><a href="#Topology创建过程" class="headerlink" title="Topology创建过程"></a>Topology创建过程</h1><p>&emsp;&emsp;Topology是storm的一个完整工作流，由spout、bolt等组件构成。下面我们来看一下Topology是如何被创建的。</p>
<h2 id="入口函数"><a href="#入口函数" class="headerlink" title="入口函数"></a>入口函数</h2><p>&emsp;&emsp;我们一般会在storm的入口函数调用TopologyBuilder进行Topology的创建，如下所示</p>
<figure class="highlight pony"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">TopologyBuilder</span> builder = <span class="function"><span class="keyword">new</span> <span class="title">TopologyBuilder</span>();</span></span><br><span class="line"><span class="function"><span class="comment">//设置spout</span></span></span><br><span class="line"><span class="function"><span class="title">builder</span>.<span class="title">setSpout</span>(<span class="type">SENTENCE_SPOUT_ID</span>, spout, <span class="number">2</span>);</span></span><br><span class="line"><span class="function"><span class="comment">//设置bolt</span></span></span><br><span class="line"><span class="function"><span class="title">builder</span>.<span class="title">setBolt</span>(<span class="type">SPLIT_BOLT_ID</span>, splitBolt, <span class="number">2</span>).<span class="title">setNumTasks</span>(<span class="number">4</span>).<span class="title">shuffleGrouping</span>(<span class="type">SENTENCE_SPOUT_ID</span>);</span></span><br><span class="line"><span class="function"><span class="title">builder</span>.<span class="title">setBolt</span>(<span class="type">COUNT_BOLT_ID</span>, countBolt, <span class="number">4</span>).<span class="title">fieldsGrouping</span>(<span class="type">SPLIT_BOLT_ID</span>, new <span class="type">Fields</span>("word"));</span></span><br><span class="line"><span class="function"><span class="title">builder</span>.<span class="title">setBolt</span>(<span class="type">REPORT_BOLT_ID</span>, reportBolt).<span class="title">globalGrouping</span>(<span class="type">COUNT_BOLT_ID</span>);</span></span><br></pre></td></tr></table></figure>
<h2 id="TopolgyBuilder"><a href="#TopolgyBuilder" class="headerlink" title="TopolgyBuilder"></a>TopolgyBuilder</h2><p>&emsp;&emsp;比较重要的实例变量</p>
<figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//所有提交的bolt放入_bolts中</span></span><br><span class="line"><span class="keyword">private</span> Map&lt;<span class="keyword">String</span>, IRichBolt&gt; _bolts = <span class="keyword">new</span> <span class="type">HashMap</span>&lt;&gt;();</span><br><span class="line"><span class="comment">//所有提交的spout放入_spouts中</span></span><br><span class="line"><span class="keyword">private</span> Map&lt;<span class="keyword">String</span>, IRichSpout&gt; _spouts = <span class="keyword">new</span> <span class="type">HashMap</span>&lt;&gt;();</span><br><span class="line"><span class="comment">//所有topology的spout和bolt放入_commons中</span></span><br><span class="line"><span class="keyword">private</span> Map&lt;<span class="keyword">String</span>, ComponentCommon&gt; _commons = <span class="keyword">new</span> <span class="type">HashMap</span>&lt;&gt;();</span><br></pre></td></tr></table></figure>
<h3 id="setSpout"><a href="#setSpout" class="headerlink" title="setSpout"></a>setSpout</h3><figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public SpoutDeclarer setSpout(String <span class="keyword">id</span>, IRichSpout spout, Number parallelism_hint) throws IllegalArgumentException &#123;</span><br><span class="line">    <span class="comment">//检测输入id是不是唯一的，主要是从实例变量的map里看有没有对应的key存在</span></span><br><span class="line">    validateUnusedId(<span class="keyword">id</span>);</span><br><span class="line">    <span class="comment">//构建ComponentCommon对象并进行初始化，最后放入_commons中</span></span><br><span class="line">    initCommon(<span class="keyword">id</span>, spout, parallelism_hint);</span><br><span class="line">    <span class="comment">//放入_spouts中</span></span><br><span class="line">    _spouts.put(<span class="keyword">id</span>, spout);</span><br><span class="line">    <span class="keyword">return</span> new SpoutGetter(<span class="keyword">id</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="initCommon"><a href="#initCommon" class="headerlink" title="initCommon"></a>initCommon</h3><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">void</span> initCommon(String id, IComponent component, Number parallelism) throws IllegalArgumentException &#123;</span><br><span class="line">       ComponentCommon <span class="keyword">common</span> = <span class="keyword">new</span> ComponentCommon();</span><br><span class="line"><span class="comment">//设置消息流来源和分组方式</span></span><br><span class="line">       <span class="keyword">common</span>.set_inputs(<span class="keyword">new</span> HashMap&lt;GlobalStreamId, Grouping&gt;());</span><br><span class="line"><span class="comment">//设置并行度</span></span><br><span class="line">       <span class="keyword">if</span>(parallelism!=<span class="keyword">null</span>) &#123;</span><br><span class="line">           <span class="keyword">int</span> dop = parallelism.intValue();</span><br><span class="line">           <span class="keyword">if</span>(dop &lt; <span class="number">1</span>) &#123;</span><br><span class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Parallelism must be positive."</span>);</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">common</span>.set_parallelism_hint(dop);</span><br><span class="line">       &#125;</span><br><span class="line"><span class="comment">//设置组件的配置参数</span></span><br><span class="line">       Map conf = component.getComponentConfiguration();</span><br><span class="line">       <span class="keyword">if</span>(conf!=<span class="keyword">null</span>) <span class="keyword">common</span>.set_json_conf(JSONValue.toJSONString(conf));</span><br><span class="line">       _commons.put(id, <span class="keyword">common</span>);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<h3 id="setBolt"><a href="#setBolt" class="headerlink" title="setBolt"></a>setBolt</h3><p>&emsp;&emsp;与setSpout类似</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public BoltDeclarer setBolt(String <span class="built_in">id</span>, IRichBolt bolt, Number parallelism_hint) throws IllegalArgumentException &#123;</span><br><span class="line">    validateUnusedId(<span class="built_in">id</span>);</span><br><span class="line">    initCommon(<span class="built_in">id</span>, bolt, parallelism_hint);</span><br><span class="line">    _bolts.<span class="keyword">put</span>(<span class="built_in">id</span>, bolt);</span><br><span class="line"><span class="built_in">    return</span> new BoltGetter(<span class="built_in">id</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong> setSpout和setBolt区别 </strong> </p>
<p>看上去二者完成的事情基本类似，但是返回值有区别</p>
<p>SpoutGetter的源码</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">protected</span> <span class="class"><span class="keyword">class</span> <span class="title">SpoutGetter</span> <span class="keyword">extends</span> <span class="title">ConfigGetter&lt;SpoutDeclarer&gt;</span> <span class="title">implements</span> <span class="title">SpoutDeclarer</span> </span>&#123;</span><br><span class="line">    public <span class="type">SpoutGetter</span>(<span class="type">String</span> id) &#123;</span><br><span class="line">        <span class="keyword">super</span>(id);</span><br><span class="line">    &#125;        </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而BoltGetter源码</p>
<figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">protected <span class="class"><span class="keyword">class</span> <span class="title">BoltGetter</span> <span class="keyword"><span class="keyword">extends</span> <span class="type">ConfigGetter</span></span>&lt;<span class="title">BoltDeclarer</span>&gt; <span class="keyword"><span class="keyword">implements</span> <span class="type">BoltDeclarer</span></span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">String</span> _boltId;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> BoltGetter(<span class="keyword">String</span> boltId) &#123;</span><br><span class="line">        <span class="keyword">super</span>(boltId);</span><br><span class="line">        _boltId = boltId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> BoltDeclarer fieldsGrouping(<span class="keyword">String</span> componentId, Fields fields) &#123;</span><br><span class="line">        <span class="keyword">return</span> fieldsGrouping(componentId, Utils.DEFAULT_STREAM_ID, fields);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> BoltDeclarer fieldsGrouping(<span class="keyword">String</span> componentId, <span class="keyword">String</span> streamId, Fields fields) &#123;</span><br><span class="line">        <span class="keyword">return</span> grouping(componentId, streamId, Grouping.fields(fields.toList()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> BoltDeclarer globalGrouping(<span class="keyword">String</span> componentId) &#123;</span><br><span class="line">        <span class="keyword">return</span> globalGrouping(componentId, Utils.DEFAULT_STREAM_ID);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> BoltDeclarer globalGrouping(<span class="keyword">String</span> componentId, <span class="keyword">String</span> streamId) &#123;</span><br><span class="line">        <span class="keyword">return</span> grouping(componentId, streamId, Grouping.fields(<span class="keyword">new</span> <span class="type">ArrayList</span>&lt;<span class="keyword">String</span>&gt;()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> BoltDeclarer shuffleGrouping(<span class="keyword">String</span> componentId) &#123;</span><br><span class="line">        <span class="keyword">return</span> shuffleGrouping(componentId, Utils.DEFAULT_STREAM_ID);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> BoltDeclarer shuffleGrouping(<span class="keyword">String</span> componentId, <span class="keyword">String</span> streamId) &#123;</span><br><span class="line">        <span class="keyword">return</span> grouping(componentId, streamId, Grouping.shuffle(<span class="keyword">new</span> <span class="type">NullStruct</span>()));</span><br><span class="line">    &#125;</span><br><span class="line">	</span><br><span class="line">    .....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以发现BoltGetter还实现了不同的分组方式，如</p>
<figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">private</span> BoltDeclarer grouping(<span class="keyword">String</span> componentId, <span class="keyword">String</span> streamId, Grouping grouping) &#123;</span><br><span class="line">    _commons.<span class="keyword">get</span>(_boltId).put_to_inputs(<span class="keyword">new</span> <span class="type">GlobalStreamId</span>(componentId, streamId), grouping);</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>分组的本质是在_common中通过对应的boltId找到对应的ComponentCommon对象，对inputs属性进行设置。</p>
<h3 id="createTopology"><a href="#createTopology" class="headerlink" title="createTopology()"></a>createTopology()</h3><p>&emsp;&emsp;TopologyBuilder中还有一个比较重要的方法–createTopology()，其主要完成最后的封装工作。</p>
<figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   <span class="keyword">public</span> StormTopology createTopology() &#123;</span><br><span class="line"><span class="comment">//bolt集合</span></span><br><span class="line">       Map&lt;<span class="keyword">String</span>, Bolt&gt; boltSpecs = <span class="keyword">new</span> <span class="type">HashMap</span>&lt;&gt;();</span><br><span class="line"><span class="comment">//spout集合</span></span><br><span class="line">       Map&lt;<span class="keyword">String</span>, SpoutSpec&gt; spoutSpecs = <span class="keyword">new</span> <span class="type">HashMap</span>&lt;&gt;();</span><br><span class="line">       maybeAddCheckpointSpout();</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">String</span> boltId: <span class="type">_bolts</span>.keySet()) &#123;</span><br><span class="line">    <span class="comment">//通过boltId获取Bolt</span></span><br><span class="line">           IRichBolt bolt = _bolts.<span class="keyword">get</span>(boltId);</span><br><span class="line">           bolt = maybeAddCheckpointTupleForwarder(bolt);</span><br><span class="line">    <span class="comment">//设置对应ComponentCommon对象的streams属性(输出的字段列表是否为直接流)</span></span><br><span class="line">           ComponentCommon common = getComponentCommon(boltId, bolt);</span><br><span class="line">           <span class="keyword">try</span>&#123;</span><br><span class="line">               maybeAddCheckpointInputs(common);</span><br><span class="line">	<span class="comment">//把bolt和common一起放入bolt集合</span></span><br><span class="line">               boltSpecs.put(boltId, <span class="keyword">new</span> <span class="type">Bolt</span>(ComponentObject.serialized_java(Utils.javaSerialize(bolt)), common));</span><br><span class="line">           &#125;<span class="keyword">catch</span>(RuntimeException wrapperCause)&#123;</span><br><span class="line">               <span class="keyword">if</span> (wrapperCause.getCause() != <span class="literal">null</span> &amp;&amp; NotSerializableException.class.equals(wrapperCause.getCause().getClass()))&#123;</span><br><span class="line">                   <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(</span><br><span class="line">                       <span class="string">"Bolt '"</span> + boltId + <span class="string">"' contains a non-serializable field of type "</span> + wrapperCause.getCause().getMessage() + <span class="string">", "</span> +</span><br><span class="line">                       <span class="string">"which was instantiated prior to topology creation. "</span> + wrapperCause.getCause().getMessage() + <span class="string">" "</span> +</span><br><span class="line">                       <span class="string">"should be instantiated within the prepare method of '"</span> + boltId + <span class="string">" at the earliest."</span>, wrapperCause);</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="keyword">throw</span> wrapperCause;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line"><span class="comment">//对spout的处理和bolt的处理基本一致</span></span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">String</span> spoutId: <span class="type">_spouts</span>.keySet()) &#123;</span><br><span class="line">           IRichSpout spout = _spouts.<span class="keyword">get</span>(spoutId);</span><br><span class="line">           ComponentCommon common = getComponentCommon(spoutId, spout);</span><br><span class="line">           <span class="keyword">try</span>&#123;</span><br><span class="line">               spoutSpecs.put(spoutId, <span class="keyword">new</span> <span class="type">SpoutSpec</span>(ComponentObject.serialized_java(Utils.javaSerialize(spout)), common));</span><br><span class="line">           &#125;<span class="keyword">catch</span>(RuntimeException wrapperCause)&#123;</span><br><span class="line">               <span class="keyword">if</span> (wrapperCause.getCause() != <span class="literal">null</span> &amp;&amp; NotSerializableException.class.equals(wrapperCause.getCause().getClass()))&#123;</span><br><span class="line">                   <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(</span><br><span class="line">                       <span class="string">"Spout '"</span> + spoutId + <span class="string">"' contains a non-serializable field of type "</span> + wrapperCause.getCause().getMessage() + <span class="string">", "</span> +</span><br><span class="line">                       <span class="string">"which was instantiated prior to topology creation. "</span> + wrapperCause.getCause().getMessage() + <span class="string">" "</span> +</span><br><span class="line">                       <span class="string">"should be instantiated within the prepare method of '"</span> + spoutId + <span class="string">" at the earliest."</span>, wrapperCause);</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="keyword">throw</span> wrapperCause;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       StormTopology stormTopology = <span class="keyword">new</span> <span class="type">StormTopology</span>(spoutSpecs,</span><br><span class="line">               boltSpecs,</span><br><span class="line">               <span class="keyword">new</span> <span class="type">HashMap</span>&lt;<span class="keyword">String</span>, StateSpoutSpec&gt;());</span><br><span class="line"></span><br><span class="line">       stormTopology.set_worker_hooks(_workerHooks);</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> Utils.addVersions(stormTopology);</span><br></pre></td></tr></table></figure>
<p>最终我们设置的bolt和spout都被封装到了StormTopology中。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;总的来讲TopologyBuilder就是根据分组方式把spout和bolt节点连接起来形成一个拓扑结构。</p>

          
        
      
    </div>
    
    
    



    

    <div>
      
    </div>

    <div>
      
    </div>

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yajian.github.io/storm系列2-并行度和资源分配/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小建儿">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小建儿的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/storm系列2-并行度和资源分配/" itemprop="url">storm系列2:并行度和资源分配</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-22T15:02:19+08:00">
                2018-08-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/storm/" itemprop="url" rel="index">
                    <span itemprop="name">storm</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/storm系列2-并行度和资源分配/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="storm系列2-并行度和资源分配/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="并行度相关概念"><a href="#并行度相关概念" class="headerlink" title="并行度相关概念"></a>并行度相关概念</h1><p>&emsp;&emsp;和spark driver、work、executor一样，storm也有一套自己的概念。Storm集群中的节点可以分为两类：主节点nimbus，从节点supervisor。nimbus主要负责分配计算资源，supervisor主要负责执行client提交的任务。supervisor节点在运行任务时，涉及到以下三个概念：worker、executor、task。</p>
<h2 id="worker"><a href="#worker" class="headerlink" title="worker"></a>worker</h2><p>&emsp;&emsp;supervisor在执行任务时，会启动一个或者多个jvm进程，这些进程统称为worker。默认情况下一个supervisor最多可以启动4个worker，也可以通过修改storm.yaml参数进行修改。因为topology最终都是通过worker来执行的，所以nimbus并不关心有几个supervisor，只关心有多少个worker，至于worker分配在哪个节点上，nimbus是不关心的。需要说明的是，一个worker只能同时运行一个topology，如果在该worker运行时又有topology提交，nimbus会将其分配给其他空闲的worker。</p>
<h2 id="executor"><a href="#executor" class="headerlink" title="executor"></a>executor</h2><p>&emsp;&emsp;在一个jvm进程中，有时候我们会开启多个线程执行任务，这里executor的概念就是线程的概念。</p>
<h2 id="task"><a href="#task" class="headerlink" title="task"></a>task</h2><p>&emsp;&emsp;executor中运行的topology的一个component，如spout、bolt，叫做task，task是storm中进行计算的最小运行单位，表示spout和bolt的运行实例。</p>
<h1 id="资源设置的注意事项"><a href="#资源设置的注意事项" class="headerlink" title="资源设置的注意事项"></a>资源设置的注意事项</h1><h2 id="worker-1"><a href="#worker-1" class="headerlink" title="worker"></a>worker</h2><p>&emsp;&emsp;worker个数的增加，会导致worker之间数据传输时间增加。如果程序瓶颈在于待处理的元组数据太多算力不足，那么通过可以通过增加worker个数提高计算效率。</p>
<h2 id="executor-1"><a href="#executor-1" class="headerlink" title="executor"></a>executor</h2><p>&emsp;&emsp;executor是真正的并行度。executor初始数量=spout数量+bolt数量+acker数量，也就是task个数，默认一个executor对应一个task。其中spout、bolt、acker数量运行时是不会变化的，但是executor数量是可以变化的。</p>
<h2 id="task-1"><a href="#task-1" class="headerlink" title="task"></a>task</h2><p>&emsp;&emsp;task的存在是为了topology扩展的灵活性，与并行度无关。task在实际执行数据处理。如果单纯提高task个数，不增加executor个数，并不一定能提高性能。提高task任务数量，可以为后期进行弹性计算（rebalance）即后期动态调整某一组件的并行度。</p>
<h1 id="并行度计算"><a href="#并行度计算" class="headerlink" title="并行度计算"></a>并行度计算</h1><p>计算并行度官网有个比较好的例子</p>
<div align="center"><br><img src="/storm系列2-并行度和资源分配/并行度计算.jpg" width="400" height="300" title="并行度计算"><br></div>

<p>上图中，有2个worker进程，</p>
<ul>
<li>蓝色的BlueSpout有2个executor进程，每个executor有1个task，并行度为2；</li>
<li>绿色的GreenBolt有2个executor进程，每个executor有2个task，并行度为2；</li>
<li>黄色的YellowBolt有6个executor进程，每个executor有1个task，并行度为6；</li>
<li>上图总平行度是2+2+6=10，具体分配到每个worker上就是5个</li>
</ul>

          
        
      
    </div>
    
    
    



    

    <div>
      
    </div>

    <div>
      
    </div>

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yajian.github.io/设计模式-状态模式/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小建儿">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小建儿的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/设计模式-状态模式/" itemprop="url">设计模式-状态模式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-18T17:12:26+08:00">
                2018-08-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/设计模式/" itemprop="url" rel="index">
                    <span itemprop="name">设计模式</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/设计模式-状态模式/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="设计模式-状态模式/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="状态模式"><a href="#状态模式" class="headerlink" title="状态模式"></a>状态模式</h1><p>&emsp;&emsp;很多情况下，一个对象的行为取决于一个或多个状态变化的属性，这样的属性叫状态。这样的对象叫做有状态的对象，这样的状态是从事先定义好的一系列值中获取的。当一个这样的对象与外部产生互动时，其内部状态就会改变，从而使得系统的行为也随之发生改变。</p>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><h2 id="环境类"><a href="#环境类" class="headerlink" title="环境类"></a>环境类</h2><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public class Context &#123;</span><br><span class="line">    private State <span class="keyword">state</span>;</span><br><span class="line"></span><br><span class="line">    public State getState() &#123;</span><br><span class="line">        return <span class="keyword">state</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void <span class="built_in">set</span>State(State <span class="keyword">state</span>) &#123;</span><br><span class="line">        this.<span class="keyword">state</span> = <span class="keyword">state</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="抽象状态接口"><a href="#抽象状态接口" class="headerlink" title="抽象状态接口"></a>抽象状态接口</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public<span class="built_in"> interface </span>State &#123;</span><br><span class="line"></span><br><span class="line">    void handle(Context context);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="具体状态类"><a href="#具体状态类" class="headerlink" title="具体状态类"></a>具体状态类</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StartState</span> <span class="keyword">implements</span> <span class="title">State</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"player is in start state"</span>);</span><br><span class="line">        context.setState(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"start state"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StopState</span> <span class="keyword">implements</span> <span class="title">State</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"player is in stop state"</span>);</span><br><span class="line">        context.setState(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"stop state"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="测试类"><a href="#测试类" class="headerlink" title="测试类"></a>测试类</h2><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public void test() &#123;</span><br><span class="line">    <span class="built_in">Context</span> <span class="built_in">context</span> = new <span class="built_in">Context</span>()<span class="comment">;</span></span><br><span class="line"></span><br><span class="line">    StartState startState = new StartState()<span class="comment">;</span></span><br><span class="line">    startState.handle(<span class="built_in">context</span>)<span class="comment">;</span></span><br><span class="line"></span><br><span class="line">    StopState stopState = new StopState()<span class="comment">;</span></span><br><span class="line">    stopState.handle(<span class="built_in">context</span>)<span class="comment">;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结果</p>
<figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">player is <span class="keyword">in</span> start <span class="keyword">state</span></span><br><span class="line">player is <span class="keyword">in</span> stop <span class="keyword">state</span></span><br></pre></td></tr></table></figure>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;状态模式和命令模式一样，可以用于消除if-else等条件选择语句。</p>
<ul>
<li>优点</li>
</ul>
<p>&emsp;&emsp;封装了状态转换规则，状态转换代码可以封装在环境类或者具体状态类中，可以对状态转换代码进行集中管理，而不是分散在一个个业务代码中。</p>
<p>&emsp;&emsp;将所有与状态有关的行为放到一个类中，只需要注入不同的状态对象即可是环境对象拥有不同的行为。</p>
<p>&emsp;&emsp;允许状态转换逻辑与状态对象合成一体，而不是提供一个巨大的条件语句块，状态模式可以让我们避免使用庞大的条件语句来讲业务方法和状态转换代码交织在一起。</p>
<ul>
<li>缺点</li>
</ul>
<p>&emsp;&emsp;增加系统内类的个数。<br>&emsp;&emsp;实现复杂，增加系统设计难度<br>&emsp;&emsp;对“开闭原则”支持不好，增加新的状态类需要修改负责状态转换的代码。</p>

          
        
      
    </div>
    
    
    



    

    <div>
      
    </div>

    <div>
      
    </div>

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yajian.github.io/设计模式-命令模式/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小建儿">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小建儿的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/设计模式-命令模式/" itemprop="url">设计模式-命令模式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-18T11:57:07+08:00">
                2018-08-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/设计模式/" itemprop="url" rel="index">
                    <span itemprop="name">设计模式</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/设计模式-命令模式/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="设计模式-命令模式/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h1><p>&emsp;&emsp;在软件设计中，我们经常需要向某些对象发送请求，但是并不知道请求的接收者是谁，也不知道被请求的操作是哪个。我们只需在程序运行时指定具体的请求接收者即可，此时可以使用命令模式来进行设计，使得请求发送者和接受者之间消除耦合，让对象的调用关系更加灵活。</p>
<p>&emsp;&emsp;命令模式可以对发送者和接受者完全解耦，发送者和接受者之间没有直接引用关系，发送请求的对象只需要知道如何发送请求，而不必知道如何完成请求。这就是命令模式的动机。</p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><h2 id="命令的执行者"><a href="#命令的执行者" class="headerlink" title="命令的执行者"></a>命令的执行者</h2><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">Light</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">on</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">        System.<span class="keyword">out</span>.println(<span class="string">"灯打开了"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">off</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line">        System.<span class="keyword">out</span>.println(<span class="string">"灯关了"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="抽象命令接口"><a href="#抽象命令接口" class="headerlink" title="抽象命令接口"></a>抽象命令接口</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public<span class="built_in"> interface </span>Command &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    void execute();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="具体命令实现类"><a href="#具体命令实现类" class="headerlink" title="具体命令实现类"></a>具体命令实现类</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LightOffCommand</span> <span class="keyword">implements</span> <span class="title">Command</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Light light;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LightOffCommand</span><span class="params">(Light light)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.light = light;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        light.off();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LightOnCommand</span> <span class="keyword">implements</span> <span class="title">Command</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Light light;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LightOnCommand</span><span class="params">(Light light)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.light = light;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        light.on();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="调用者类"><a href="#调用者类" class="headerlink" title="调用者类"></a>调用者类</h2><p>这里假设为遥控器</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Controller</span> &#123;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Command command;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCommand</span><span class="params">(Command command)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.command = command;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buttonOnPressed</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        command.execute();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="测试类"><a href="#测试类" class="headerlink" title="测试类"></a>测试类</h2><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">public</span> void test() &#123;</span><br><span class="line">        Controller controller = <span class="keyword">new</span> <span class="type">Controller</span>();</span><br><span class="line">        Light light = <span class="keyword">new</span> <span class="type">Light</span>();</span><br><span class="line">        LightOffCommand lightOffCommand = <span class="keyword">new</span> <span class="type">LightOffCommand</span>(light);</span><br><span class="line">        LightOnCommand lightOnCommand = <span class="keyword">new</span> <span class="type">LightOnCommand</span>(light);</span><br><span class="line"></span><br><span class="line">        controller.setCommand(lightOffCommand);</span><br><span class="line">        controller.buttonOnPressed();</span><br><span class="line">        controller.setCommand(lightOnCommand);</span><br><span class="line">        controller.buttonOnPressed();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">灯关了</span></span><br><span class="line"><span class="comment">灯打开了</span></span><br><span class="line"><span class="comment">**/</span></span><br></pre></td></tr></table></figure>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>命令模式的好处在于可以将命令的请求这和命令的执行者进行解耦，但是在复杂场景下，命令类会变得很多，不方便进行管理。</p>

          
        
      
    </div>
    
    
    



    

    <div>
      
    </div>

    <div>
      
    </div>

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yajian.github.io/storm系列1-storm集群搭建/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小建儿">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小建儿的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/storm系列1-storm集群搭建/" itemprop="url">storm系列1:storm集群搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-16T17:17:14+08:00">
                2018-08-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/storm/" itemprop="url" rel="index">
                    <span itemprop="name">storm</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/storm系列1-storm集群搭建/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="storm系列1-storm集群搭建/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;最近在研究流式特征处理，所以搭建了storm集群环境，把过程发出来，以备后续查看。</p>
<h1 id="安装包准备"><a href="#安装包准备" class="headerlink" title="安装包准备"></a>安装包准备</h1><ul>
<li><p>jdk: oracle官网下载的jdk1.8.0_181版本</p>
</li>
<li><p>zookeeper: zookeeper下载的zookeeper-3.4.12版本</p>
</li>
<li><p>storm： storm下载的apache-storm-1.2.2版本</p>
</li>
</ul>
<h1 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HOME/.local/bin:$HOME/bin</span><br><span class="line"><span class="attribute">JAVA_HOME</span>=/home/user/jdk1.8.0_181</span><br><span class="line"><span class="attribute">JRE_HOME</span>=<span class="variable">$JAVA_HOME</span>/jre</span><br><span class="line"><span class="attribute">STORM_HOME</span>=/home/user/apache-storm-1.2.2</span><br><span class="line"><span class="attribute">CLASSPATH</span>=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="attribute">ZOOKEEPER_HOME</span>=/home/user/zookeeper-3.4.12</span><br><span class="line"><span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$JAVA_HOME/bin:$STORM_HOME/bin:$ZOOKEEPER_HOME/bin</span><br><span class="line"><span class="builtin-name">export</span> PATH</span><br><span class="line"><span class="builtin-name">export</span> JAVA_HOME</span><br><span class="line"><span class="builtin-name">export</span> JRE_HOME</span><br><span class="line"><span class="builtin-name">export</span> CLASSPATH</span><br><span class="line"><span class="builtin-name">export</span> ZOOKEEPER_HOME</span><br><span class="line"><span class="builtin-name">export</span> STORM_HOME</span><br></pre></td></tr></table></figure>
<h1 id="配置zookeeper"><a href="#配置zookeeper" class="headerlink" title="配置zookeeper"></a>配置zookeeper</h1><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>&emsp;&emsp;zookeeper需要修改ZOOKEEPER_HOME/conf/zoo.cfg文件，加入下列信息</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="attribute">tickTime</span>=2000</span><br><span class="line"><span class="attribute">dataDir</span>=/var/zookeeper/</span><br><span class="line"><span class="attribute">clientPort</span>=2181</span><br><span class="line"><span class="attribute">initLimit</span>=5</span><br><span class="line"><span class="attribute">syncLimit</span>=2</span><br><span class="line">server.<span class="attribute">1</span>=m7-pce-hdp01:2888:3888 </span><br><span class="line">server.<span class="attribute">2</span>=m7-pce-hdp02:2888:3888 </span><br><span class="line">server.<span class="attribute">3</span>=m7-pce-hdp03:2888:3888</span><br></pre></td></tr></table></figure>
<p>其中dataDir是zookeeper的数据文件目录；server.id=host:port:port，其中id是每个节点的编号，这个编号需要在dataDir目录下创建myid文件中写入，m7-pce-hdp01~m7-pce-hdp03是hostname，第一个port用于连接leader的端口，第二个port用于连接leader的选举端口。</p>
<h2 id="启动zookeeper"><a href="#启动zookeeper" class="headerlink" title="启动zookeeper"></a>启动zookeeper</h2><p>执行ZOOKEEPER_HOME/bin/zkServer.sh启动zookeeper，并执行zkServer.sh status，查看是否启动成功</p>
<h1 id="配置storm"><a href="#配置storm" class="headerlink" title="配置storm"></a>配置storm</h1><p>&emsp;&emsp;storm配置文件在STORM_HOME/conf/storm.yaml，需要配置一下几个信息</p>
<h2 id="配置zookeeper列表"><a href="#配置zookeeper列表" class="headerlink" title="配置zookeeper列表"></a>配置zookeeper列表</h2><figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">storm.zookeeper.servers:</span><br><span class="line">    -<span class="ruby"> <span class="string">"m7-pce-hdp01"</span></span></span><br><span class="line"><span class="ruby">    - <span class="string">"m7-pce-hdp02"</span></span></span><br><span class="line"><span class="ruby">    - <span class="string">"m7-pce-hdp03"</span></span></span><br></pre></td></tr></table></figure>
<h2 id="配置nimbus"><a href="#配置nimbus" class="headerlink" title="配置nimbus"></a>配置nimbus</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">nimbus<span class="selector-class">.seeds</span>: [<span class="string">"m7-pce-hdp01"</span>]</span><br></pre></td></tr></table></figure>
<h2 id="配置storm本地dir"><a href="#配置storm本地dir" class="headerlink" title="配置storm本地dir"></a>配置storm本地dir</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">storm<span class="selector-class">.local</span><span class="selector-class">.dir</span>: <span class="string">"/home/user/apache-storm-1.2.2/workdir"</span></span><br></pre></td></tr></table></figure>
<h2 id="配置supervisor-slots-ports"><a href="#配置supervisor-slots-ports" class="headerlink" title="配置supervisor.slots.ports"></a>配置supervisor.slots.ports</h2><p> supervisor.slots.ports是指每个机器可以启动多少个worker，一个端口号代表一个worker</p>
<figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">supervisor.slots.ports:</span><br><span class="line">     -<span class="ruby"> <span class="number">6700</span></span></span><br><span class="line"><span class="ruby">     - <span class="number">6701</span></span></span><br><span class="line"><span class="ruby">     - <span class="number">6702</span></span></span><br><span class="line"><span class="ruby">     - <span class="number">6703</span></span></span><br></pre></td></tr></table></figure>
<h1 id="启动Storm集群"><a href="#启动Storm集群" class="headerlink" title="启动Storm集群"></a>启动Storm集群</h1><h2 id="启动nimbus集群"><a href="#启动nimbus集群" class="headerlink" title="启动nimbus集群"></a>启动nimbus集群</h2><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">nohup storm nimbus <span class="meta">&amp;</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;用jps查看后台线程会发现多了nimbus（先显示config value，配置正确后变成nimbus）</p>
<h2 id="启动supervisor"><a href="#启动supervisor" class="headerlink" title="启动supervisor"></a>启动supervisor</h2><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">nohup storm supervisor <span class="meta">&amp;</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;用jps查看后台线程出现Supervisor</p>
<h2 id="启动监控ui"><a href="#启动监控ui" class="headerlink" title="启动监控ui"></a>启动监控ui</h2><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">nohup storm ui <span class="meta">&amp;</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;用jps查看后台线程出现core</p>
<p>在浏览器中输入“<a href="http://m7-pce-hdp01:8080/index.html”即可看到" target="_blank" rel="noopener">http://m7-pce-hdp01:8080/index.html”即可看到</a></p>
<h1 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h1><p>&emsp;&emsp;集群配置完，我们开始向集群提交任务。</p>
<h2 id="配置本地storm"><a href="#配置本地storm" class="headerlink" title="配置本地storm"></a>配置本地storm</h2><p>&emsp;&emsp;需要在storm.yaml文件中配置nimbus</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">nimbus<span class="selector-class">.host</span>: <span class="string">"m7-pce-hdp01"</span></span><br></pre></td></tr></table></figure>
<h2 id="准备程序"><a href="#准备程序" class="headerlink" title="准备程序"></a>准备程序</h2><p>&emsp;&emsp;在STORM_HOME/examples下有很多示例代码，我们选用storm-starter进行测试。这里需要用maven进行打包，执行mvn package就行。然后我们就能在target文件夹下找到storm-starter-1.2.2.jar，一会就提交它。</p>
<h2 id="提交任务-1"><a href="#提交任务-1" class="headerlink" title="提交任务"></a>提交任务</h2><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">storm jar storm-starter<span class="number">-1.2</span><span class="number">.2</span>.jar storm/starter/StatefulTopology wordcountexample</span><br></pre></td></tr></table></figure>
<p>然后输入storm list</p>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">2703 [main] INFO  o.a.s.u.NimbusClient - Found leader nimbus : m7-pce-hdp01:6627</span><br><span class="line">Topology<span class="emphasis">_name        Status     Num_</span>tasks  Num<span class="emphasis">_workers  Uptime_</span>secs</span><br><span class="line">-------------------------------------------------------------------</span><br><span class="line">wordcountexample     ACTIVE     7          1            183702</span><br></pre></td></tr></table></figure>
<p>也可以进入ui页面进行查看运行状态。storm任务运行完也不会停止，需要手动kill。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;以上就是storm集群的搭建过程，很简单，基本上没遇到什么问题。</p>

          
        
      
    </div>
    
    
    



    

    <div>
      
    </div>

    <div>
      
    </div>

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="小建儿">
            
              <p class="site-author-name" itemprop="name">小建儿</p>
              <p class="site-description motion-element" itemprop="description">码农小白成长记</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">51</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">小建儿</span>

  
</div>

<div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
    本站访客数:<span id="busuanzi_value_site_uv"></span> |
  </span>
</div>

<!-- 
  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io" rel="external nofollow">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next" rel="external nofollow">NexT.Pisces</a> v5.1.3</div>



<% if (page.mathjax){ %>
<%- partial('mathjax') %>
<% } %>
-->
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">| 博客全站共字</span>
</div>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  



  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  

    
      <script id="dsq-count-scr" src="https://.disqus.com/count.js" async></script>
    

    

  




	





  
    

    
  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  
    <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  
</body>
</html>
